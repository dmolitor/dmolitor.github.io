{
  "hash": "aa0edc693ff6f2dff92f4916a4424275",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Robust Adaptive Experiments\"\ndescription: |\n  Exploring the MAD design <a href=\"https://arxiv.org/abs/2311.05794\">(Liang and Bojinov, 2024)</a> and extending it to balance anytime-valid inference, reward maximization, and statistical power in adaptive experiments.\ndate: \"2/11/2025\"\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-overflow: scroll\nexecute: \n  freeze: true\n  warning: false\n  message: false\njupyter: python3\npage-layout: article\ncategories: [Bandits, Adaptive Experiments]\nimage: \"./thumbnail.jpg\"\n---\n\n\nRecently I've been thinking about how to design adaptive experiments that\nenable valid inference on treatment effects while maintaining sufficient power\nto detect nonzero effects across treatment arms (including sub-optimal arms).\nTo explore this, I will run simulations demonstrating how we can achieve these\ngoals. Specifically, I extend the Mixture Adaptive Design (MAD)\n[(Liang & Bojinov, 2024)](https://arxiv.org/abs/2311.05794) to produce an\nadaptive experiment with the following properties:\n\n- **Anytime-valid inference on the ATE**, allowing experiments to stop upon\nreaching statistical significance.\n- **Dynamic sample allocation**, ensuring all treatment arms receive enough\nsamples for adequate power.\n- **Efficiency gains via bandit design**, balancing statistical power with\nbandit objectives (e.g., reward maximization).\n\n### Dependencies\n\n::: {#776e451b .cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport plotnine as pn\nfrom scipy.stats import t\nfrom tqdm import tqdm\n\nfrom src.bandit import TSBernoulli\nfrom src.mad import MAD, MADModified\nfrom src.utils import last\n```\n:::\n\n\n\n\n## Introducing the MAD\n\nThe MAD combines Bernoulli randomization with arbitrary multi-armed bandit\n(MAB) algorithms, enabling unbiased ATE estimation with anytime-valid\nconfidence sequences (CSs).\n\nTo illustrate its usefulness, consider a simple experiment with one control\nand one treatment arm. Outcomes are sampled as follows:\n\n- Control arm: Y ∼ Bernoulli($\\theta$=0.5)\n- Treatment arm: Y∼Bernoulli($\\theta$=0.6)\n- True ATE: 0.1\n\nWe use Thompson Sampling (TS) as the bandit algorithm and stop the experiment\nas soon as the ATE reaches statistical significance.\n\n::: {#c76b9371 .cell execution_count=3}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\ngenerator = np.random.default_rng(seed=123)\n\ndef reward_fn(arm: int) -> float:\n    values = {\n        0: generator.binomial(1, 0.5),\n        1: generator.binomial(1, 0.6)  # ATE = 0.1\n    }\n    return values[arm]\n\nexp_simple = MAD(\n    bandit=TSBernoulli(k=2, control=0, reward=reward_fn),\n    alpha=0.05,\n    delta=lambda x: 1./(x**0.24),\n    t_star=int(30e3)\n)\nexp_simple.fit(cs_precision=0, verbose=False)\n```\n:::\n\n\nFinally, we plot the MAD-estimated ATE over time, showing convergence to the\ntrue effect and demonstrating that the corresponding 95% CSs maintain valid\ncoverage.\n\n::: {#1bb577ad .cell execution_count=4}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\n(\n    exp_simple.plot_ate_path()\n    + pn.coord_cartesian(ylim=(-.5, 1.5))\n    + pn.geom_hline(\n        mapping=pn.aes(yintercept=\"ate\", color=\"factor(arm)\"),\n        data=pd.DataFrame({\"arm\": list(range(1, 2)), \"ate\": [0.1]}),\n        linetype=\"dotted\"\n    )\n    + pn.theme(strip_text=pn.element_blank()) \n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=750 height=300}\n:::\n:::\n\n\n### Bandit benefits\n\nThe underlying bandit algorithm provides additional benefits. Below, we show\nthe total sample size assigned to both arms of the experiment:\n\n::: {#98357ee6 .cell execution_count=5}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nexp_simple.plot_n()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=750 height=300}\n:::\n:::\n\n\nand the arm assignment probability over time:\n\n::: {#c169148a .cell execution_count=6}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nexp_simple.plot_probabilities()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=750 height=300}\n:::\n:::\n\n\nThe TS algorithm assigns the majority of the sample to the optimal arm\n(Arm 1 is the treatment). This demonstrates how we can achieve both valid ATE\ninference and reward maximization with the bandit algorithm.\n\n### Limitations\n\nIn adaptive experiments with multiple treatment arms, a common issue is being\nunder-powered to detect non-zero ATEs in sub-optimal arms. This happens because\nthe bandit algorithm allocates most of the sample to the optimal arm(s),\nneglecting the others.\n\nWe demonstrate this with an experiment simulating a control arm and four\ntreatment arms with ATEs of 0.1, 0.12, 0.3, and 0.32, respectively, over a\nfixed sample size of 20,000. We expect the bandit algorithm to allocate most of\nthe sample to arms 3 and 4, leaving arms 1 and 2 under-powered.\n\n::: {#7adb968b .cell execution_count=7}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\ndef reward_fn(arm: int) -> float:\n    values = {\n        0: generator.binomial(1, 0.5),  # Control arm\n        1: generator.binomial(1, 0.6),  # ATE = 0.1\n        2: generator.binomial(1, 0.62), # ATE = 0.12\n        3: generator.binomial(1, 0.8),  # ATE = 0.3\n        4: generator.binomial(1, 0.82)  # ATE = 0.32\n    }\n    return values[arm]\n\nexp_complex = MAD(\n    bandit=TSBernoulli(k=5, control=0, reward=reward_fn),\n    alpha=0.05,\n    delta=lambda x: 1./(x**0.24),\n    t_star=int(20e3)\n)\nexp_complex.fit(early_stopping=False, verbose=False)\n\nates = pd.concat(\n    [\n        exp_complex.estimates().assign(which=\"mad\"),\n        pd.DataFrame({\n            \"arm\": list(range(1, 5)),\n            \"ate\": [0.1, 0.12, 0.3, 0.32],\n            \"which\": [\"truth\"]*(4)\n        })\n    ],\n    axis=0\n)\n(\n    pn.ggplot(\n        ates,\n        mapping=pn.aes(\n            x=\"factor(arm)\",\n            y=\"ate\",\n            ymin=\"lb\",\n            ymax=\"ub\",\n            color=\"which\"\n        )\n    )\n    + pn.geom_point(position=pn.position_dodge(width=0.3))\n    + pn.geom_errorbar(position=pn.position_dodge(width=0.3), width=0.001)\n    + pn.geom_hline(yintercept=0, linetype=\"dashed\", color=\"black\")\n    + pn.theme_538()\n    + pn.labs(x=\"Arm\", y=\"ATE\", color=\"Method\")\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){width=750 height=300}\n:::\n:::\n\n\nAs anticipated, we observe strong ATE estimates for arms 3 and 4 but\nunder-powered estimates for arms 1 and 2 (CSs include 0). We can confirm that,\nindeed, TS focuses the majority of the sample on arms 3 and 4 to the detriment\nof power in our experiment.\n\n::: {#06d2d297 .cell execution_count=8}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nexp_complex.plot_n()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.png){width=750 height=300}\n:::\n:::\n\n\n## MAD modified\n\nI propose an extension of the MAD algorithm to address the challenge of\ninadequate power in sub-optimal arms. For each treatment arm $k \\in K$\nand time period $t$, I introduce importance weights $w_{tk} \\in [0, 1]$. Once \nthe estimated ATE for arm $k$ becomes statistically significant, $w_{tk}$\nbegins to shrink toward zero according to a user-defined function of $t$.\n\nIn the notation of Liang and Bojinov, let $A$ represent an arbitrary adaptive\nalgorithm. They define $p_t^A(k)$ as the assignment probability for arm $k$ at\ntime $t$ under $A$. By construction, the set $p_t^A(k)$ of\nadaptive assignment probabilities for all $k \\in K$ forms a valid probability\ndistribution over $K$, meaning $\\sum_{k \\in K}{p_t^A(k)}=1$. I modify these \nprobabilities to $g(p_t^A(k))$ where $g$ re-weights $p_t^A(k)$ based on the\nimportance weight $w_{tk}$.\n\nFor each treatment arm $k \\in K$ at time $t$, the re-weighted probability\n$g(p_t^A(k))$ is computed as follows:\n\n1.) **Apply Importance Weights**:\nEach probability is first scaled by its importance weight:\n$$p_t^*(k)=w_{tk}*p_t^A(k).$$\n\n2.) **Compute Lost Probability Mass**:\nThe probability mass lost due to down-weighting is:\n$$L_t = \\sum_{k \\in K}{p_t^A(k)*(1 - w_{tk})}.$$\n\n3.) **Compute Relative Redistribution Weights**:\nThe total weight sum is: $$W_t = \\sum_{k \\in K}{w_{tk}}.$$ Each arm's share of\n    the remaining mass is: $$r_{tk} = \\frac{w_{tk}}{W_t}.$$\n\n4.) **Redistribute Lost Mass**: Redistribute the lost mass proportionally to\nthe relative weights: $$p_t^g(k) = p_t^*(k) + (r_{tk} * L_t).$$\n\n5.) **Normalization Check**: Since $p_t^g(k)$ for all $k \\in K$ forms\na valid probability distribution over $K$, it satisfies: $$\\sum_{k \\in K}p_t^g(k)=1.$$\n\nThus, the function $g$ modifies the original assignment probabilities by\nscaling each by its importance weight and redistributing the lost probability\nmass in a manner that preserves the total probability sum.\n\n### User-Specified Decay of Importance Weights\n\nThe importance weight function $w_{tk}$​ controls how quickly the assignment\nprobability for arm $k$ shrinks once its estimated ATE becomes statistically\nsignificant. This user-defined function balances two extremes:\n\n- $w_{tk}=1$ for all $t$, which keeps $g(p_t^A(k))=p_t^A(k)$, making the\nalgorithm identical to the original MAD design.\n- $w_{tk}=0$ after arm $k$ reaches statistical significance,\nredirecting all future probability mass away from arm $k$ and prioritizing\nunderpowered arms.\n- More generally, the user defines $w_{tk}$ somewhere in between, where:\n    - A slower decay of $w_{tk}$ (closer to 1) retains more influence from the\n    adaptive algorithm’s assignment probabilities.\n    - A faster decay (closer to 0) shifts the algorithm toward prioritizing\n    underpowered arms at the expense of bandit goals\n    (e.g. reward maximization).\n\nReasonable choices for $w_{tk}$ include polynomial or exponential decay,\nproviding flexibility in tuning sample reallocation.\n\n## Algorithm comparison\n\nI compare the two algorithms to highlight the benefits of the modified\napproach. The modified algorithm significantly improves power to detect\nnon-zero ATEs in all treatment arms and provides more precise ATE estimates\nthan the original MAD algorithm with the same sample size. However, this comes\nat the cost of assigning more sample to sub-optimal arms, where \"optimal\" is\ndefined by the underlying bandit algorithm.\n\n### Improved power and precision\n\nThe following plots demonstrate the increased power and precision of the\nmodified MAD algorithm.\n\n::: {#d3568503 .cell execution_count=9}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\n# Run the modified algorithm\nmad_modified = MADModified(\n    bandit=TSBernoulli(k=5, control=0, reward=reward_fn),\n    alpha=0.05,\n    delta=lambda x: 1./(x**0.24),\n    t_star=int(20e3),\n    decay=lambda x: 1./(x**(1./8.))\n)\nmad_modified.fit(cs_precision=0.1, verbose=False, early_stopping=True)\n\n# Run the vanilla algorithm\nmad_vanilla = MAD(\n    bandit=TSBernoulli(k=5, control=0, reward=reward_fn),\n    alpha=0.05,\n    delta=lambda x: 1./(x**0.24),\n    t_star=mad_modified._bandit._t\n)\nmad_vanilla.fit(verbose=False, early_stopping=False)\n\n# Compare the ATEs and CSs\nates = pd.concat(\n    [\n        mad_modified.estimates().assign(which=\"MADMod\"),\n        mad_vanilla.estimates().assign(which=\"MAD\"),\n        pd.DataFrame({\n            \"arm\": list(range(1, 5)),\n            \"ate\": [0.1, 0.12, 0.3, 0.32],\n            \"which\": [\"Truth\"]*(4)\n        })\n    ],\n    axis=0\n)\n(\n    pn.ggplot(\n        ates,\n        mapping=pn.aes(\n            x=\"factor(arm)\",\n            y=\"ate\",\n            ymin=\"lb\",\n            ymax=\"ub\",\n            color=\"which\"\n        )\n    )\n    + pn.geom_point(position=pn.position_dodge(width=0.3))\n    + pn.geom_errorbar(position=pn.position_dodge(width=0.3), width=0.001)\n    + pn.geom_hline(yintercept=0, linetype=\"dashed\", color=\"black\")\n    + pn.theme_538()\n    + pn.labs(x=\"Arm\", y=\"ATE\", color=\"Method\")\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=750 height=300}\n:::\n:::\n\n\nAnd the following plot compares the sample assignment to the treatment arms\nof the two algorithms:\n\n::: {#95179b17 .cell execution_count=10}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nsample_sizes = pd.concat([\n    pd.DataFrame(x) for x in\n    [\n        {\n            \"arm\": [k for k in range(len(mad_modified._ate))],\n            \"n\": [last(n) for n in mad_modified._n],\n            \"which\": [\"MADMod\"]*len(mad_modified._ate)\n        },\n        {\n            \"arm\": [k for k in range(len(mad_vanilla._ate))],\n            \"n\": [last(n) for n in mad_vanilla._n],\n            \"which\": [\"MAD\"]*len(mad_vanilla._ate)\n        }\n    ]\n])\n(\n    pn.ggplot(sample_sizes, pn.aes(x=\"factor(arm)\", y=\"n\", fill=\"which\", color=\"which\"))\n    + pn.geom_bar(stat=\"identity\", position=pn.position_dodge(width=0.75), width=0.7)\n    + pn.theme_538()\n    + pn.labs(x=\"Arm\", y=\"N\", color=\"Method\", fill=\"Method\")\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-1.png){width=750 height=300}\n:::\n:::\n\n\n### Simulation results over 1,0000 runs\n\nWe can more precisely quantify the improvements by running 1,000 simulations,\ncomparing Type 2 error and confidence band width between the vanilla MAD\nalgorithm and the modified algorithm. Each simulation runs for 20,000\niterations with early stopping. If the modified algorithm stops early, the\nvanilla algorithm will also stop early to maintain equal sample sizes in each\nsimulation.\n\n::: {#33091dd6 .cell execution_count=11}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\ndef delta_fn(x):\n    return 1. / (x ** 0.24)\n\ndef decay_fn(x):\n    return 1. / (x ** (1. / 8.))\n\ndef compare(i):\n    mad_modified = MADModified(\n        bandit=TSBernoulli(k=5, control=0, reward=reward_fn),\n        alpha=0.05,\n        delta=delta_fn,\n        t_star=int(2e4),\n        decay=decay_fn\n    )\n    mad_modified.fit(cs_precision=0.1, verbose=False, early_stopping=True)\n\n    # Run the vanilla algorithm\n    mad_vanilla = MAD(\n        bandit=TSBernoulli(k=5, control=0, reward=reward_fn),\n        alpha=0.05,\n        delta=delta_fn,\n        t_star=mad_modified._bandit._t\n    )\n    mad_vanilla.fit(verbose=False, early_stopping=False)\n\n    # Calculate the Type 2 error and the Confidence Sequence width\n\n    ## For modified algorithm\n    mad_mod_n = (\n        pd\n        .DataFrame([\n            {\"arm\": k, \"n\": last(mad_modified._n[k])}\n            for k in range(mad_modified._bandit.k())\n            if k != mad_modified._bandit.control()\n        ])\n        .assign(\n            n_pct=lambda x: x[\"n\"].apply(lambda y: y/np.sum(x[\"n\"]))\n        )\n    )\n    mad_mod_df = (\n        mad_modified\n        .estimates()\n        .assign(\n            idx=i,\n            method=\"modified\",\n            width=lambda x: x[\"ub\"] - x[\"lb\"],\n            error=lambda x: ((0 > x[\"lb\"]) & (0 < x[\"ub\"]))\n        )\n        .merge(mad_mod_n, on=\"arm\", how=\"left\")\n    )\n\n    ## For vanilla algorithm\n    mad_van_n = (\n        pd\n        .DataFrame([\n            {\"arm\": k, \"n\": last(mad_vanilla._n[k])}\n            for k in range(mad_vanilla._bandit.k())\n            if k != mad_vanilla._bandit.control()\n        ])\n        .assign(\n            n_pct=lambda x: x[\"n\"].apply(lambda y: y/np.sum(x[\"n\"]))\n        )\n    )\n    mad_van_df = (\n        mad_vanilla\n        .estimates()\n        .assign(\n            idx=i,\n            method=\"mad\",\n            width=lambda x: x[\"ub\"] - x[\"lb\"],\n            error=lambda x: ((0 > x[\"lb\"]) & (0 < x[\"ub\"]))\n        )\n        .merge(mad_van_n, on=\"arm\", how=\"left\")\n    )\n\n    out = {\n        \"metrics\": pd.concat([mad_mod_df, mad_van_df]),\n        \"reward\": {\n            \"modified\": np.sum(mad_modified._rewards),\n            \"mad\": np.sum(mad_vanilla._rewards)\n        }\n    }\n    return out\n\n# Execute in parallel with joblib\ncomparison_results_list = [\n    x for x in\n    joblib.Parallel(return_as=\"generator\", n_jobs=-1)(\n        joblib.delayed(compare)(i) for i in range(100)\n    )\n]\n\n# Compare performance on key metrics across simulations\nmetrics_df = pd.melt(\n    (\n        pd\n        .concat([x[\"metrics\"] for x in comparison_results_list])\n        .reset_index(drop=True)\n        .assign(error=lambda x: x[\"error\"].apply(lambda y: int(y)))\n    ),\n    id_vars=[\"arm\", \"method\"],\n    value_vars=[\"width\", \"error\", \"n\", \"n_pct\"],\n    var_name=\"meas\",\n    value_name=\"value\"\n)\n\n# Compare reward accumulation across simulations\nreward_df = pd.melt(\n    pd.DataFrame([x[\"reward\"] for x in comparison_results_list]),\n    value_vars=[\"modified\", \"mad\"],\n    var_name=\"method\",\n    value_name=\"reward\"\n)\n\nmetrics_summary = (\n    metrics_df\n    .groupby([\"arm\", \"method\", \"meas\"], as_index=False).agg(\n        mean=(\"value\", \"mean\"),\n        std=(\"value\", \"std\"),\n        n=(\"value\", \"count\")\n    )\n    .assign(\n        se=lambda x: x[\"std\"] / np.sqrt(x[\"n\"]),\n        t_val=lambda x: t.ppf(0.975, x[\"n\"] - 1),\n        ub=lambda x: x[\"mean\"] + x[\"t_val\"] * x[\"se\"],\n        lb=lambda x: x[\"mean\"] - x[\"t_val\"] * x[\"se\"]\n    )\n    .drop(columns=[\"se\", \"t_val\"])\n)\n```\n:::\n\n\nThe following plot shows the mean (and 95% confidence intervals) of the Type 2\nerror and CS width for both algorithms.\n\n::: {#417ba8f2 .cell execution_count=12}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\nfacet_labels = {\n    \"error\": \"Type 2 error\",\n    \"width\": \"Interval width\",\n    \"n\": \"Sample size\",\n    \"n_pct\": \"Sample size %\"\n}\n(\n    pn.ggplot(\n        metrics_summary[metrics_summary[\"meas\"].isin([\"error\", \"width\"])],\n        pn.aes(\n            x=\"factor(arm)\",\n            y=\"mean\",\n            ymin=\"lb\",\n            ymax=\"ub\",\n            color=\"method\"\n        )\n    )\n    + pn.geom_point(position=pn.position_dodge(width=0.2))\n    + pn.geom_errorbar(position=pn.position_dodge(width=0.2), width=0.01)\n    + pn.facet_wrap(\n        \"~ meas\",\n        labeller=lambda x: facet_labels[x],\n        scales=\"free\"\n    )\n    + pn.theme_538()\n    + pn.labs(x=\"Arm\", y=\"\", color=\"Method\")\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){width=750 height=300}\n:::\n:::\n\n\nThe modified MAD algorithm achieves far lower Type 2 error and improved\nATE precision in all treatment arms.\n\n### Tradeoffs\n\nThese plots illustrate the tradeoffs of the modified algorithm. On average,\nit allocates significantly more sample to sub-optimal arms compared to the\nstandard MAD algorithm.\n\n::: {#fc05de57 .cell execution_count=13}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\n(\n    pn.ggplot(\n        metrics_summary[metrics_summary[\"meas\"].isin([\"n\", \"n_pct\"])],\n        pn.aes(\n            x=\"factor(arm)\",\n            y=\"mean\",\n            ymin=\"lb\",\n            ymax=\"ub\",\n            color=\"method\"\n        )\n    )\n    + pn.geom_point(position=pn.position_dodge(width=0.2))\n    + pn.geom_errorbar(position=pn.position_dodge(width=0.2), width=0.01)\n    + pn.facet_wrap(\n        \"~ meas\",\n        labeller=lambda x: facet_labels[x],\n        scales=\"free\"\n    )\n    + pn.theme_538()\n    + pn.labs(x=\"Arm\", y=\"\", color=\"Method\")\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-1.png){width=750 height=300}\n:::\n:::\n\n\nAs a result, this reallocation reduces total reward accumulation. The\ndifference in accumulated reward across the 1,000 simulations is shown below:\n\n::: {#2960088d .cell execution_count=14}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show the code\"}\n(\n    pn.ggplot(reward_df, pn.aes(x=\"method\", y=\"reward\"))\n    + pn.geom_boxplot()\n    + pn.theme_538()\n    + pn.labs(x=\"Method\", y=\"Cumulative reward\")\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-1.png){width=750 height=300}\n:::\n:::\n\n\n## Summary\n\nIn summary, this approach allows us to achieve\n**anytime-valid inference on the ATE**, enabling early stopping for greater\nflexibility and efficiency. It also allows us to\n**ensure dynamic sample allocation**, guaranteeing sufficient power for all\n(or the top n) treatment arms.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}