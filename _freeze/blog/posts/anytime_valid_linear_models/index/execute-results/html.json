{
  "hash": "b049692e54e695efa609e6f45946140d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Anytime-Valid Regression Adjusted Causal Inference\"\ndescription: |\n  Investigating the methods described in <a href=\"https://arxiv.org/abs/2210.08589\">Anytime-Valid Linear Models and Regression Adjusted Causal Inference in Randomized Experiments\n  by Lindon, et al.</a> via simulations.\ndate: \"2/21/2025\"\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-overflow: scroll\n    fig-width: 7\n    fig-height: 4\n    fig-dpi: 300\nexecute: \n  freeze: true\npage-layout: full\ncategories: [Anytime-valid Inference]\nimage: \"./thumbnail.jpg\"\n---\n\n\n\nRandomized experiments (A/B tests) are ubiquitous in both academia and the\ntech sector. Randomization allows us to perform robust causal inference\non the impact of interventions on user/participant outcomes. In particular,\nunder randomization, a variety of estimators give us valid and robust inference\non the average treatment effect (ATE), $E[Y_i(1) - Y_i(0)].$ Many common\ntests for statistically significant differences between the ATE and some\npre-specified baseline (most commonly 0) give theoretical guarantees on\nType 1 error control. That is, $\\sup_{h \\in H_0} \\mathbb{P}(\\text{rejects } H_0 | H_0) <= \\alpha$ where\n$\\alpha$ is the significance level (commonly set to $\\alpha=0.5$).\n\n## Simulate RCT\n\n### Dependencies\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(slider)\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n## Simulate RCT with ATE of 0.5\ndraw <- function(arm, ate = 2.0, sigma = 1.0) {\n  covar_coef <- c(2, 1.2, 0.4)\n  covar <- rbinom(3, size = 1, prob = c(0.1, 0.5, 0.9))\n  y <- 0.5 + ate*arm + drop(covar_coef %*% covar) + rnorm(1, 0, sigma)\n  cbind(data.frame(\"y\" = y, \"t\" = arm), data.frame(t(covar)))\n}\n\ncompare <- function(model, unadjusted_model, data, iter, ate = 2.0) {\n  seq_f <- sequential_f_cs(model, phi = 10)\n  seq_f_unadjusted <- sequential_f_cs(unadjusted_model, phi = 10)\n  seq_asymp <- ate_cs_asymp(model, treat_name = \"t\", lambda = 100)\n  seq_asymp_unadjusted <- ate_cs_asymp(\n    unadjusted_model,\n    lambda = 100,\n    treat_name = \"t\"\n  )\n  comparison_df <- data.frame(\n    \"i\" = iter,\n    \"method\" = c(\n      \"f_test\",\n      \"f_test_unadj\",\n      \"asymp\",\n      \"asymp_unadj\"\n    #   \"lm\",\n    #   \"lm_unadj\"\n    ),\n    \"estimate\" = c(\n      subset(seq_f, covariate == \"t\")$estimate,\n      subset(seq_f_unadjusted, covariate == \"t\")$estimate,\n      seq_asymp$estimate,\n      seq_asymp_unadjusted$estimate\n    #   coef(model)[[\"t\"]],\n    #   coef(unadjusted_model)[[\"t\"]]\n    ),\n    \"lower\" = c(\n      subset(seq_f, covariate == \"t\")$cs_lower,\n      subset(seq_f_unadjusted, covariate == \"t\")$cs_lower,\n      seq_asymp$cs_lower,\n      seq_asymp_unadjusted$cs_lower\n    #   confint(model)[\"t\", ][[1]],\n    #   confint(unadjusted_model)[\"t\", ][[1]]\n    ),\n    \"upper\" = c(\n      subset(seq_f, covariate == \"t\")$cs_upper,\n      subset(seq_f_unadjusted, covariate == \"t\")$cs_upper,\n      seq_asymp$cs_upper,\n      seq_asymp_unadjusted$cs_upper\n    #   confint(model)[\"t\", ][[2]],\n    #   confint(unadjusted_model)[\"t\", ][[2]]\n    )\n  )\n  comparison_df$covered <- (\n    comparison_df$lower <= ate & ate <= comparison_df$upper\n  )\n  return(comparison_df)\n}\n\nsimulate <- function(model_fn, model_unadj_fn, draw_fn, n, ate) {\n  # Warm-start with 20 observations so that no regression coefs are NA\n  # at any point\n  df <- do.call(rbind, lapply(1:20, function(x) draw_fn(ate)))\n  estimates <- data.frame()\n  for (i in 1:n) {\n    observation <- draw_fn(ate)\n    df <- rbind(df, observation)\n    model <- model_fn(df)\n    unadjusted_model <- model_unadj_fn(df)\n    estimates <- rbind(\n      estimates,\n      compare(model, unadjusted_model, df, iter = i, ate = ate)\n    )\n  }\n  estimates <- estimates |> \n    mutate(\n      stat_sig = 0 < lower | 0 > upper,\n      method = case_when(\n        method == \"asymp\" ~ \"Sequential asymptotic CS\",\n        method == \"asymp_unadj\" ~ \"Sequential asymptotic CS w/o covariates\",\n        method == \"f_test\" ~ \"Sequential CS\",\n        method == \"f_test_unadj\" ~ \"Sequential CS w/o covariates\",\n        method == \"lm\" ~ \"Fixed-N CS\",\n        method == \"lm_unadj\" ~ \"Fixed-N CS w/o covariates\"\n      )\n    ) |>\n    group_by(method) |>\n    mutate(transition = (!lag(stat_sig, default = FALSE)) & stat_sig) |>\n    mutate(\n      stat_sig_i_min = if_else(\n        any(stat_sig & !lag(stat_sig, default = FALSE)),\n        min(i[stat_sig & !lag(stat_sig, default = FALSE)]),\n        NA_integer_\n      ),\n      stat_sig_i_max = if_else(\n        any(transition),\n        max(i[transition]),\n        NA_integer_\n      )  \n    ) |>\n    ungroup()\n  return(estimates)\n}\n\n# Simulation estimates\nestimates <- simulate(\n  model_fn = function(data) lm(y ~ ., data),\n  model_unadj_fn = function(data) lm(y ~ t, data),\n  draw_fn = function(ate) draw(rbinom(1, 1, 0.5), ate = ate),\n  n = 500,\n  ate = 0.5\n)\n\n# Compare F-test CSs and Asymptotic CSs\nggplot(estimates, aes(x = i, y = estimate, ymin = lower, ymax = upper)) +\n  geom_line(size = 0.2) +\n  geom_ribbon(alpha = 0.5) +\n  geom_hline(yintercept = 0.5, linetype = \"dotted\", color = \"red\") +\n  geom_vline(aes(xintercept = stat_sig_i_max), linetype = \"dashed\", color = \"blue\") +\n  facet_wrap(\n    ~ method,\n    ncol = 2,\n    scales = \"free\",\n  ) +\n  coord_cartesian(ylim = c(-0.5, 2)) +\n  labs(y = \"ATE\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=2100}\n:::\n:::\n\n\n\nAnd we can check the empirical coverage; that is, the fraction of CSs that\ncontain the true ATE.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# Coverage across N\nestimates |>\n  group_by(method) |>\n  summarize(coverage = mean(covered, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  method                                  coverage\n  <chr>                                      <dbl>\n1 Sequential CS                                  1\n2 Sequential CS w/o covariates                   1\n3 Sequential asymptotic CS                       1\n4 Sequential asymptotic CS w/o covariates        1\n```\n\n\n:::\n:::\n\n\n\n\n## Simulate non-fixed-probability randomized data (but known propensity scores)\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ndraw_prop <- function(ate = 2.0, sigma = 1.0) {\n  prop_covar_coef <- c(0.5, 0.3, 0.1)\n  prop_covar <- rbinom(3, size = 1, prob = c(0.1, 0.4, 0.7))\n  prop <- drop(prop_covar_coef %*% prop_covar) + 0.05\n  covar_coef <- c(3, 2, 1)\n  covar <- rbinom(3, size = 1, prob = c(0.25, 0.5, 0.75))\n  arm <- rbinom(1, 1, prop)\n  y <- (\n    0.5\n    + ate*arm\n    + drop(covar_coef %*% covar)\n    + drop(prop_covar_coef %*% prop_covar)\n    + rnorm(1, 0, sigma)\n  )\n  cbind(data.frame(\"y\" = y, \"t\" = arm, \"p\" = ifelse(arm, prop, 1 - prop)), data.frame(t(covar)))\n}\n\n# Simulation estimates\nestimates <- simulate(\n  model_fn = function(data) lm(y ~ . - p, data, weights = 1/data$p),\n  model_unadj_fn = function(data) lm(y ~ t, data, weights = 1/data$p),\n  draw_fn = function(ate) draw_prop(ate = ate),\n  n = 2000,\n  ate = 0.5\n)\n\nggplot(\n  estimates,\n  aes(x = i, y = estimate, ymin = lower, ymax = upper)\n) +\n  geom_line(size = 0.2) +\n  geom_ribbon(alpha = 0.5) +\n  geom_hline(yintercept = 0.5, linetype = \"dotted\", color = \"red\") +\n  geom_vline(aes(xintercept = stat_sig_i_max), linetype = \"dashed\", color = \"blue\") +\n  facet_wrap(\n    ~ method,\n    ncol = 2,\n    scales = \"free\",\n  ) +\n  coord_cartesian(ylim = c(-0.5, 2)) +\n  labs(y = \"ATE\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=2100}\n:::\n:::\n\n\n\nAgain; empirical coverage:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nestimates |>\n  group_by(method) |>\n  summarize(coverage = mean(covered, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  method                                  coverage\n  <chr>                                      <dbl>\n1 Sequential CS                                  1\n2 Sequential CS w/o covariates                   1\n3 Sequential asymptotic CS                       1\n4 Sequential asymptotic CS w/o covariates        1\n```\n\n\n:::\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}