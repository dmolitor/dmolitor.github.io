---
title: "Housing Prices Prediction"
summary: "The goal of this short project is to document a fairly realistic ML pipeline, including data cleaning, data visualization, and model development, in both R and Python."
author: "Daniel Molitor"
date: "2022-02-03"
output: md_document
categories: ["R", "Python", "ML"]
image:
  caption: ""
  focal_point: ""
  placement: 2
  preview_only: false
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>The goal of this short project is to document a fairly realistic ML pipeline, including data cleaning, data visualization, and model development, in both R and Python.</p>
<div id="python" class="section level1">
<h1>Python</h1>
<div id="requisite-modules" class="section level2">
<h2>Requisite modules</h2>
<pre class="python"><code>import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedShuffleSplit
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.tree import DecisionTreeRegressor</code></pre>
</div>
<div id="import-data" class="section level2">
<h2>Import data</h2>
<pre class="python"><code>housing = pd.read_csv(
  &quot;https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv&quot;
)

# Get data structure
housing.info()</code></pre>
<pre><code># &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
# RangeIndex: 20640 entries, 0 to 20639
# Data columns (total 10 columns):
#  #   Column              Non-Null Count  Dtype  
# ---  ------              --------------  -----  
#  0   longitude           20640 non-null  float64
#  1   latitude            20640 non-null  float64
#  2   housing_median_age  20640 non-null  float64
#  3   total_rooms         20640 non-null  float64
#  4   total_bedrooms      20433 non-null  float64
#  5   population          20640 non-null  float64
#  6   households          20640 non-null  float64
#  7   median_income       20640 non-null  float64
#  8   median_house_value  20640 non-null  float64
#  9   ocean_proximity     20640 non-null  object 
# dtypes: float64(9), object(1)
# memory usage: 1.6+ MB</code></pre>
<p>We can also quickly summarize the housing data.</p>
<pre class="python"><code>housing.describe()</code></pre>
<pre><code>#           longitude      latitude  ...  median_income  median_house_value
# count  20640.000000  20640.000000  ...   20640.000000        20640.000000
# mean    -119.569704     35.631861  ...       3.870671       206855.816909
# std        2.003532      2.135952  ...       1.899822       115395.615874
# min     -124.350000     32.540000  ...       0.499900        14999.000000
# 25%     -121.800000     33.930000  ...       2.563400       119600.000000
# 50%     -118.490000     34.260000  ...       3.534800       179700.000000
# 75%     -118.010000     37.710000  ...       4.743250       264725.000000
# max     -114.310000     41.950000  ...      15.000100       500001.000000
# 
# [8 rows x 9 columns]</code></pre>
<p>Now that we have a quick overview of the data, we can plot a histogram of all
numeric values.</p>
<pre class="python"><code>housing.hist(bins = 50, figsize = (30, 15));
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Numeric%20Hist-1.png" width="2880" /></p>
<p>We’re going to bin the <code>median_income</code> variable to allow for stratified sampling
within income bins.</p>
<pre class="python"><code>housing[&quot;median_income_bin&quot;] = pd.cut(
  housing[&quot;median_income&quot;],
  bins = [0, 1.5, 3, 4.5, 6, np.inf],
  labels = [1, 2, 3, 4, 5]
)

# Plot histogram of counts
housing[&quot;median_income_bin&quot;].hist();
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Cut%20Income-3.png" width="2880" /></p>
</div>
<div id="visualize-data" class="section level2">
<h2>Visualize data</h2>
<p>Now, let’s visualize the median house prices by plotting them geographically.</p>
<pre class="python"><code>(
  housing.
  rename(columns = {&quot;median_house_value&quot;: &quot;Median House Value&quot;}).
  plot(
    kind = &quot;scatter&quot;,
    x = &quot;longitude&quot;,
    y = &quot;latitude&quot;,
    alpha = 0.1,
    s = housing[&quot;population&quot;]/100,
    c = &quot;Median House Value&quot;,
    colormap = plt.get_cmap(&quot;jet&quot;),
    colorbar = True,
    title = &quot;Median House Prices by Population&quot;,
    xlabel = &quot;Longitude&quot;,
    ylabel = &quot;Latitude&quot;
  )
)

plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Prices%20Geo-5.png" width="672" /></p>
<p>Let’s also look at the correlation between a few of our numeric variables.</p>
<pre class="python"><code>pd.plotting.scatter_matrix(
  housing[
    [
     &quot;median_house_value&quot;,
     &quot;median_income&quot;,
     &quot;total_rooms&quot;,
     &quot;housing_median_age&quot;
    ]
  ],
  alpha = 0.1,
  figsize = (15, 8)
);

plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Cor%20Plot-7.png" width="1440" /></p>
<p>Let’s specifically take a look at the relationship between <code>median_income</code> and
<code>median_house_value</code>.</p>
<pre class="python"><code>(
  housing.
  rename(
    columns = {
      &quot;median_income&quot;: &quot;Median Income&quot;,
      &quot;median_house_value&quot;: &quot;Median House Value&quot;
    }
  ).
  plot(
    kind = &quot;scatter&quot;,
    x = &quot;Median Income&quot;,
    y = &quot;Median House Value&quot;,
    alpha = 0.1
  )
)

plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Income%20House%20Value-9.png" width="672" /></p>
</div>
<div id="feature-engineering" class="section level2">
<h2>Feature engineering</h2>
<p>We want to create a couple new features: <code>rooms_per_household</code> and
<code>bedrooms_per_room</code>.</p>
<pre class="python"><code>housing[&quot;rooms_per_household&quot;] = housing[&quot;total_rooms&quot;]/housing[&quot;households&quot;]
housing[&quot;bedrooms_per_room&quot;] = housing[&quot;total_bedrooms&quot;]/housing[&quot;total_rooms&quot;]
housing[&quot;pop_per_household&quot;] = housing[&quot;population&quot;]/housing[&quot;households&quot;]</code></pre>
</div>
<div id="modeling-prep" class="section level2">
<h2>Modeling prep</h2>
<p>Let’s do an 70-30 split of the data initially.</p>
<pre class="python"><code>split = StratifiedShuffleSplit(
  n_splits = 1,
  test_size = 0.3,
  random_state = 123
)

for train_idx, test_idx in split.split(housing, housing[&quot;median_income_bin&quot;]):
  train = housing.loc[train_idx].drop(
    [&quot;median_income_bin&quot;, &quot;median_house_value&quot;],
    axis = 1
  )
  train_labels = housing.loc[train_idx, &quot;median_house_value&quot;]
  test = housing.loc[test_idx].drop(
    [&quot;median_income_bin&quot;, &quot;median_house_value&quot;],
    axis = 1
  )
  test_labels = housing.loc[test_idx, &quot;median_house_value&quot;]</code></pre>
<p>Now, let’s prep the data for modeling.</p>
<pre class="python"><code># Numeric transformations
num_transform = Pipeline(
  [
    (&quot;imputer&quot;, SimpleImputer(strategy = &quot;median&quot;)),
    (&quot;scaler&quot;, StandardScaler())
  ]
)

full_transform = ColumnTransformer(
  [
    (
     &quot;numeric&quot;,
     num_transform,
     list(train.drop(&quot;ocean_proximity&quot;, axis = 1).columns)
    ),
    (&quot;categorical&quot;, OneHotEncoder(), [&quot;ocean_proximity&quot;])
  ]
)

train = full_transform.fit_transform(train)
test = full_transform.transform(test)</code></pre>
</div>
<div id="train-models" class="section level2">
<h2>Train models</h2>
<p>Let’s quick chalk up a function to print CV metrics.</p>
<pre class="python"><code>def metrics_summary(scores):
  print(&quot;Mean: &quot;, scores.mean().round(2))
  print(&quot;Standard Dev.: &quot;, scores.std().round(2))</code></pre>
<div id="linear-regression" class="section level3">
<h3>Linear Regression</h3>
<p>The first model is a simple linear regression model.</p>
<pre class="python"><code># Fit model
lin_reg_scores = np.sqrt(
  -cross_val_score(
     LinearRegression(),
     train,
     train_labels,
     scoring = &quot;neg_mean_squared_error&quot;,
     cv = 10
   )
)

# Summarize score info
metrics_summary(lin_reg_scores)</code></pre>
<pre><code># Mean:  68005.1
# Standard Dev.:  2417.76</code></pre>
</div>
<div id="decision-tree" class="section level3">
<h3>Decision Tree</h3>
<p>The next model is a single decision tree model.</p>
<pre class="python"><code># Fit model
tree_reg = np.sqrt(
  -cross_val_score(
     DecisionTreeRegressor(),
     train,
     train_labels,
     scoring = &quot;neg_mean_squared_error&quot;,
     cv = 10
   )
)

# Summarize score info
metrics_summary(tree_reg)</code></pre>
<pre><code># Mean:  71631.6
# Standard Dev.:  2614.03</code></pre>
</div>
<div id="random-forest" class="section level3">
<h3>Random Forest</h3>
<p>Now, we will run a random forest model.</p>
<pre class="python"><code># Fit model
forest_reg = np.sqrt(
  -cross_val_score(
     RandomForestRegressor(n_estimators = 30),
     train,
     train_labels,
     scoring = &quot;neg_mean_squared_error&quot;,
     cv = 10
   )
)

# Summarize score info
metrics_summary(forest_reg)</code></pre>
<pre><code># Mean:  51298.21
# Standard Dev.:  1698.51</code></pre>
<p>And finally, we will tune our random forest model via grid search.</p>
<pre class="python"><code># Fit model
forest_reg_grid = GridSearchCV(
  RandomForestRegressor(),
  param_grid = {
    &quot;n_estimators&quot;: [30],
    &quot;min_samples_leaf&quot;: [5],
    &quot;max_features&quot;: [&quot;sqrt&quot;]
  },
  scoring = &quot;neg_mean_squared_error&quot;,
  cv = 5,
  return_train_score = True
)

forest_reg_grid_fit = forest_reg_grid.fit(train, train_labels)

# Get CV results
cv_results = forest_reg_grid_fit.cv_results_

# Summarize score info
for mean_sc, param in zip(cv_results[&quot;mean_test_score&quot;], cv_results[&quot;params&quot;]):
  print(&quot;Mean: &quot;, np.sqrt(-mean_sc).round(2))
  print(&quot;Parameters: &quot;, param)</code></pre>
<pre><code># Mean:  51821.79
# Parameters:  {&#39;max_features&#39;: &#39;sqrt&#39;, &#39;min_samples_leaf&#39;: 5, &#39;n_estimators&#39;: 30}</code></pre>
</div>
</div>
<div id="final-predictions" class="section level2">
<h2>Final predictions</h2>
<pre class="python"><code># Extract model
final_model = forest_reg_grid_fit.best_estimator_

# Make predictions
final_preds = final_model.predict(test)

# Final RMSE
print(
  &quot;Test RMSE: &quot;, np.sqrt(mean_squared_error(test_labels, final_preds)).round(2)
)</code></pre>
<pre><code># Test RMSE:  50810.13</code></pre>
</div>
</div>
<div id="r" class="section level1">
<h1>R</h1>
<div id="requisite-packages" class="section level2">
<h2>Requisite packages</h2>
<pre class="r"><code>library(dplyr)
library(ggplot2)
library(purrr)
library(ranger)
library(readr)
library(rpart)
library(rsample)
library(sf)
library(tidyr)
library(viridis)
library(yardstick)</code></pre>
</div>
<div id="import-data-1" class="section level2">
<h2>Import data</h2>
<pre class="r"><code>housing &lt;- read_csv(
  &quot;https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv&quot;,
  show_col_types = FALSE
)

# Get data structure
glimpse(housing)</code></pre>
<pre><code># Rows: 20,640
# Columns: 10
# $ longitude          &lt;dbl&gt; -122.23, -122.22, -122.24, -122.25, -122.25, -122.2~
# $ latitude           &lt;dbl&gt; 37.88, 37.86, 37.85, 37.85, 37.85, 37.85, 37.84, 37~
# $ housing_median_age &lt;dbl&gt; 41, 21, 52, 52, 52, 52, 52, 52, 42, 52, 52, 52, 52,~
# $ total_rooms        &lt;dbl&gt; 880, 7099, 1467, 1274, 1627, 919, 2535, 3104, 2555,~
# $ total_bedrooms     &lt;dbl&gt; 129, 1106, 190, 235, 280, 213, 489, 687, 665, 707, ~
# $ population         &lt;dbl&gt; 322, 2401, 496, 558, 565, 413, 1094, 1157, 1206, 15~
# $ households         &lt;dbl&gt; 126, 1138, 177, 219, 259, 193, 514, 647, 595, 714, ~
# $ median_income      &lt;dbl&gt; 8.3252, 8.3014, 7.2574, 5.6431, 3.8462, 4.0368, 3.6~
# $ median_house_value &lt;dbl&gt; 452600, 358500, 352100, 341300, 342200, 269700, 299~
# $ ocean_proximity    &lt;chr&gt; &quot;NEAR BAY&quot;, &quot;NEAR BAY&quot;, &quot;NEAR BAY&quot;, &quot;NEAR BAY&quot;, &quot;NE~</code></pre>
<p>Now, to get a quick summary of the data.</p>
<pre class="r"><code>summary(housing)</code></pre>
<pre><code>#    longitude         latitude     housing_median_age  total_rooms   
#  Min.   :-124.3   Min.   :32.54   Min.   : 1.00      Min.   :    2  
#  1st Qu.:-121.8   1st Qu.:33.93   1st Qu.:18.00      1st Qu.: 1448  
#  Median :-118.5   Median :34.26   Median :29.00      Median : 2127  
#  Mean   :-119.6   Mean   :35.63   Mean   :28.64      Mean   : 2636  
#  3rd Qu.:-118.0   3rd Qu.:37.71   3rd Qu.:37.00      3rd Qu.: 3148  
#  Max.   :-114.3   Max.   :41.95   Max.   :52.00      Max.   :39320  
#                                                                     
#  total_bedrooms     population      households     median_income    
#  Min.   :   1.0   Min.   :    3   Min.   :   1.0   Min.   : 0.4999  
#  1st Qu.: 296.0   1st Qu.:  787   1st Qu.: 280.0   1st Qu.: 2.5634  
#  Median : 435.0   Median : 1166   Median : 409.0   Median : 3.5348  
#  Mean   : 537.9   Mean   : 1425   Mean   : 499.5   Mean   : 3.8707  
#  3rd Qu.: 647.0   3rd Qu.: 1725   3rd Qu.: 605.0   3rd Qu.: 4.7432  
#  Max.   :6445.0   Max.   :35682   Max.   :6082.0   Max.   :15.0001  
#  NA&#39;s   :207                                                        
#  median_house_value ocean_proximity   
#  Min.   : 14999     Length:20640      
#  1st Qu.:119600     Class :character  
#  Median :179700     Mode  :character  
#  Mean   :206856                       
#  3rd Qu.:264725                       
#  Max.   :500001                       
# </code></pre>
<p>Now that we have a quick overview of the data, we can plot a histogram of all
numeric values.</p>
<pre class="r"><code>housing |&gt;
  select(where(is.numeric)) |&gt;
  pivot_longer(
    cols = everything(),
    names_to = &quot;variable&quot;,
    values_to = &quot;values&quot;
  ) |&gt;
  ggplot(aes(x = values)) +
  geom_histogram(fill = &quot;lightblue&quot;, bins = 50) +
  facet_wrap(
    ~ variable,
    nrow = 3,
    scales = &quot;free&quot;
  ) +
  labs(
    x = &quot;&quot;,
    y = &quot;&quot;
  ) +
  theme_minimal()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Numeric%20Hist%202-1.png" width="1440" /></p>
<p>We’re going to bin the <code>median_income</code> variable to allow for stratified sampling
within income bins.</p>
<pre class="r"><code>housing &lt;- housing |&gt;
  mutate(
    median_income_bin = cut(
      median_income,
      breaks = c(0, 1.5, 3, 4.5, 6, Inf),
      labels = c(1, 2, 3, 4, 5)
    )
  )

# Plot histogram of counts
hist(
  as.numeric(housing$median_income_bin),
  main = &quot;&quot;,
  xlab = &quot;Median Income Bin&quot;,
  ylab = &quot;Count&quot;,
  ylim = c(0, 8000)
)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Cut%20Income%202-1.png" width="672" /></p>
</div>
<div id="visualize-data-1" class="section level2">
<h2>Visualize data</h2>
<p>Now, let’s visualize the median house prices by plotting them geographically.</p>
<pre class="r"><code>housing |&gt;
  rename(
    &quot;Population&quot; = &quot;population&quot;,
    &quot;Median House Value&quot; = &quot;median_house_value&quot;
  ) |&gt;
  st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;)) |&gt;
  st_set_crs(value = 4326) |&gt;
  ggplot(
    aes(
      size = Population,
      color = `Median House Value`
    )
  ) +
  geom_sf(alpha = 0.1) +
  theme_minimal() +
  theme(
    axis.text = element_text(face = &quot;bold&quot;),
    legend.title = element_text(face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;)
  ) +
  scale_color_viridis(option = &quot;B&quot;) +
  guides(size = &quot;none&quot;) +
  labs(
    title = &quot;Median House Prices by Population&quot;,
    x = &quot;Longitude&quot;,
    y = &quot;Latitude&quot;
  )</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Prices%20Geo%202-1.png" width="1152" /></p>
<p>Let’s also look at the correlation between a few of our numeric variables.</p>
<pre class="r"><code>plot(
  select(
    housing,
    c(
      &quot;median_house_value&quot;,
      &quot;median_income&quot;,
      &quot;total_rooms&quot;,
      &quot;housing_median_age&quot;
    )
  ),
  col = rgb(red = 0, green = 0, blue = 0, alpha = 0.1)
)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Cor%20Plot%202-1.png" width="1152" /></p>
<p>Let’s specifically take a look at the relationship between <code>median_income</code> and
<code>median_house_value</code>.</p>
<pre class="r"><code>housing |&gt;
  ggplot(aes(x = median_income, y = median_house_value)) +
  geom_point(alpha = 0.1) +
  theme_minimal() +
  theme(
    axis.text = element_text(face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;)
  ) +
  labs(x = &quot;Median Income&quot;, y = &quot;Median House Value&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/Income%20House%20Value%202-1.png" width="672" /></p>
</div>
<div id="feature-engineering-1" class="section level2">
<h2>Feature engineering</h2>
<p>We want to create a couple new features: <code>rooms_per_household</code> and
<code>bedrooms_per_room</code>.</p>
<pre class="r"><code>housing &lt;- housing |&gt;
  mutate(
    rooms_per_household = total_rooms/households,
    bedrooms_per_room = total_bedrooms/total_rooms,
    pop_per_household = population/households
  )</code></pre>
</div>
<div id="modeling-prep-1" class="section level2">
<h2>Modeling prep</h2>
<p>Let’s do an 70-30 split of the data initially.</p>
<pre class="r"><code>set.seed(123)
split &lt;- initial_split(
  data = housing,
  prop = 0.7,
  strata = &quot;median_income_bin&quot;
)

train &lt;- training(split) |&gt; select(-median_income_bin)
test &lt;- testing(split) |&gt; select(-median_income_bin)</code></pre>
<p>Now, let’s prep the data for modeling.</p>
<pre class="r"><code># Get median values from training data
medians &lt;- suppressWarnings(
  lapply(train, median, na.rm = TRUE)
)

# Median impute
train &lt;- map2_df(
    .x = train,
    .y = medians,
    .f = ~ case_when(
      is.numeric(.x) ~ replace_na(.x, .y),
      TRUE ~ .x
    )
) |&gt;
  mutate(ocean_proximity = sort_factor(ocean_proximity))

test &lt;- map2_df(
    .x = test,
    .y = medians,
    .f = ~ case_when(
      is.numeric(.x) ~ replace_na(.x, .y),
      TRUE ~ .x
    )
) |&gt;
  mutate(ocean_proximity = sort_factor(ocean_proximity))</code></pre>
</div>
<div id="train-models-1" class="section level2">
<h2>Train models</h2>
<p>First, let’s split the training data into a 10-fold CV split and make a quick
function to print CV metrics.</p>
<pre class="r"><code>train_cv &lt;- vfold_cv(train, v = 10)

# Summarise CV metrics
metrics_summary &lt;- function(scores) {
  print(paste0(&quot;Mean: &quot;, round(mean(scores), 2)))
  print(paste0(&quot;Standard Dev.: &quot;, round(sd(scores), 2)))
}</code></pre>
<div id="linear-regression-1" class="section level3">
<h3>Linear Regression</h3>
<p>The first model is a simple linear regression model.</p>
<pre class="r"><code># Fit model
lin_reg_scores = map_dbl(
  train_cv$splits,
  function(i) {
    lin_mod &lt;- lm(median_house_value ~ ., data = i$data[i$in_id, ])
    lin_preds &lt;- predict(lin_mod, i$data[-i$in_id, ])
    rmse_vec(i$data[-i$in_id, ][[&quot;median_house_value&quot;]], lin_preds)
  }
)

# Summarize score info
metrics_summary(lin_reg_scores)</code></pre>
<pre><code># [1] &quot;Mean: 68071.59&quot;
# [1] &quot;Standard Dev.: 2677.06&quot;</code></pre>
</div>
<div id="decision-tree-1" class="section level3">
<h3>Decision Tree</h3>
<p>The next model is a single decision tree model.</p>
<pre class="r"><code># Fit model
tree_reg_scores = map_dbl(
  train_cv$splits,
  function(i) {
    tree_mod &lt;- rpart(median_house_value ~ ., data = i$data[i$in_id, ])
    tree_preds &lt;- predict(tree_mod, i$data[-i$in_id, ])
    rmse_vec(i$data[-i$in_id, ][[&quot;median_house_value&quot;]], tree_preds)
  }
)

# Summarize score info
metrics_summary(tree_reg_scores)</code></pre>
<pre><code># [1] &quot;Mean: 72015.68&quot;
# [1] &quot;Standard Dev.: 2842.71&quot;</code></pre>
</div>
<div id="random-forest-1" class="section level3">
<h3>Random Forest</h3>
<p>Now, we will run a random forest model.</p>
<pre class="r"><code># Fit model
forest_reg_scores = map_dbl(
  train_cv$splits,
  function(i) {
    forest_mod &lt;- ranger(median_house_value ~ ., data = i$data[i$in_id, ], 100)
    forest_preds &lt;- predict(forest_mod, i$data[-i$in_id, ])$predictions
    rmse_vec(i$data[-i$in_id, ][[&quot;median_house_value&quot;]], forest_preds)
  }
)

# Summarize score info
metrics_summary(tree_reg_scores)</code></pre>
<pre><code># [1] &quot;Mean: 72015.68&quot;
# [1] &quot;Standard Dev.: 2842.71&quot;</code></pre>
<p>And finally, we will tune our random forest model via grid search.</p>
<pre class="r"><code># Create grid
param_grid &lt;- expand.grid(num.trees = 100, mtry = 5, min.node.size = 3)

# Fit model
forest_reg_grid &lt;- map(
  1:nrow(param_grid),
  function(grid_idx) {
    map_dbl(
      train_cv$splits,
      function(cv_fold) {
        # LOO CV Model
        forest_mod &lt;- ranger(
          median_house_value ~ .,
          data = cv_fold$data[cv_fold$in_id, ],
          num.trees = param_grid[grid_idx, ]$num.trees,
          mtry = param_grid[grid_idx, ]$mtry,
          min.node.size = param_grid[grid_idx, ]$min.node.size
        )
        # OOS Predictions
        forest_preds &lt;- predict(forest_mod, cv_fold$data[-cv_fold$in_id, ])$predictions
        # Calculate RMSE
        rmse_vec(
          truth = cv_fold$data[-cv_fold$in_id, ][[&quot;median_house_value&quot;]],
          estimate = forest_preds
        )
      }
    )
  }
)

# Get best model
best_mod &lt;- which.min(map_dbl(forest_reg_grid, mean))
forest_reg_grid_fit = ranger(
  median_house_value ~ .,
  data = train,
  num.trees = param_grid[best_mod, ]$num.trees,
  mtry = param_grid[best_mod, ]$mtry,
  min.node.size = param_grid[best_mod, ]$min.node.size
)

# Summarize score info
walk(forest_reg_grid, metrics_summary)</code></pre>
<pre><code># [1] &quot;Mean: 48819.23&quot;
# [1] &quot;Standard Dev.: 1829.59&quot;</code></pre>
</div>
</div>
<div id="final-predictions-1" class="section level2">
<h2>Final predictions</h2>
<pre class="r"><code># Extract model
final_model = forest_reg_grid_fit

# Make predictions
final_preds = predict(final_model, test)$predictions

# Final RMSE
cat(
  &quot;Test RMSE:&quot;, rmse_vec(test$median_house_value, final_preds)
)</code></pre>
<pre><code># Test RMSE: 49288.67</code></pre>
</div>
</div>
