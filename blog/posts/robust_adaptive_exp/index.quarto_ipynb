{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Robust Adaptive Experiments\"\n",
        "description: |\n",
        "  Exploring the MAD design <a href=\"https://arxiv.org/abs/2311.05794\">(Liang and Bojinov, 2024)</a> and extending it to balance anytime-valid inference, reward maximization, and statistical power in adaptive experiments.\n",
        "date: \"2/11/2025\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-location: right\n",
        "    code-overflow: scroll\n",
        "execute: \n",
        "  freeze: true\n",
        "  warning: false\n",
        "  message: false\n",
        "jupyter: python3\n",
        "page-layout: article\n",
        "categories: [Adaptive Experiments, Anytime-valid Inference, Bandits]\n",
        "image: \"./thumbnail.jpg\"\n",
        "---\n",
        "\n",
        "\n",
        "Recently I've been thinking about how to design adaptive experiments that\n",
        "enable valid inference on treatment effects while maintaining sufficient power\n",
        "to detect nonzero effects across treatment arms (including sub-optimal arms).\n",
        "To explore this, I will run simulations demonstrating how we can achieve these\n",
        "goals. Specifically, I extend the Mixture Adaptive Design (MAD)\n",
        "[(Liang & Bojinov, 2024)](https://arxiv.org/abs/2311.05794) to produce an\n",
        "adaptive experiment with the following properties:\n",
        "\n",
        "- **Anytime-valid inference on the ATE**, allowing experiments to stop upon\n",
        "reaching statistical significance.\n",
        "- **Dynamic sample allocation**, ensuring all treatment arms receive enough\n",
        "samples for adequate power.\n",
        "- **Efficiency gains via bandit design**, balancing statistical power with\n",
        "bandit objectives (e.g., reward maximization).\n",
        "\n",
        "### Dependencies"
      ],
      "id": "89627f92"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotnine as pn\n",
        "from scipy.stats import t\n",
        "from tqdm import tqdm\n",
        "\n",
        "from src.bandit import TSBernoulli\n",
        "from src.mad import MAD, MADModified\n",
        "from src.utils import last"
      ],
      "id": "4f63c268",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: false\n",
        "pn.options.dpi = 150\n",
        "pn.options.figure_size = (5, 2)"
      ],
      "id": "588984f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introducing the MAD\n",
        "\n",
        "The MAD combines Bernoulli randomization with arbitrary multi-armed bandit\n",
        "(MAB) algorithms, enabling unbiased ATE estimation with anytime-valid\n",
        "confidence sequences (CSs).\n",
        "\n",
        "To illustrate its usefulness, consider a simple experiment with one control\n",
        "and one treatment arm. Outcomes are sampled as follows:\n",
        "\n",
        "- Control arm: Y ∼ Bernoulli($\\theta$=0.5)\n",
        "- Treatment arm: Y∼Bernoulli($\\theta$=0.6)\n",
        "- True ATE: 0.1\n",
        "\n",
        "We use Thompson Sampling (TS) as the bandit algorithm and stop the experiment\n",
        "as soon as the ATE reaches statistical significance."
      ],
      "id": "f514f6a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "generator = np.random.default_rng(seed=123)\n",
        "\n",
        "def reward_fn(arm: int) -> float:\n",
        "    values = {\n",
        "        0: generator.binomial(1, 0.5),\n",
        "        1: generator.binomial(1, 0.6)  # ATE = 0.1\n",
        "    }\n",
        "    return values[arm]\n",
        "\n",
        "exp_simple = MAD(\n",
        "    bandit=TSBernoulli(k=2, control=0, reward=reward_fn),\n",
        "    alpha=0.05,\n",
        "    delta=lambda x: 1./(x**0.24),\n",
        "    t_star=int(30e3)\n",
        ")\n",
        "exp_simple.fit(cs_precision=0, verbose=False)"
      ],
      "id": "99b9e6e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we plot the MAD-estimated ATE over time, showing convergence to the\n",
        "true effect and demonstrating that the corresponding 95% CSs maintain valid\n",
        "coverage."
      ],
      "id": "5dc1ee44"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "(\n",
        "    exp_simple.plot_ate_path()\n",
        "    + pn.coord_cartesian(ylim=(-.5, 1.5))\n",
        "    + pn.geom_hline(\n",
        "        mapping=pn.aes(yintercept=\"ate\", color=\"factor(arm)\"),\n",
        "        data=pd.DataFrame({\"arm\": list(range(1, 2)), \"ate\": [0.1]}),\n",
        "        linetype=\"dotted\"\n",
        "    )\n",
        "    + pn.theme(strip_text=pn.element_blank()) \n",
        ")"
      ],
      "id": "f762e4ea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bandit benefits\n",
        "\n",
        "The underlying bandit algorithm provides additional benefits. Below, we show\n",
        "the total sample size assigned to both arms of the experiment:"
      ],
      "id": "f58c9755"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "exp_simple.plot_n()"
      ],
      "id": "10871baa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the arm assignment probability over time:"
      ],
      "id": "3d8f9938"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "exp_simple.plot_probabilities()"
      ],
      "id": "c4827faf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The TS algorithm assigns the majority of the sample to the optimal arm\n",
        "(Arm 1 is the treatment). This demonstrates how we can achieve both valid ATE\n",
        "inference and reward maximization with the bandit algorithm.\n",
        "\n",
        "### Limitations\n",
        "\n",
        "In adaptive experiments with multiple treatment arms, a common issue is being\n",
        "under-powered to detect non-zero ATEs in sub-optimal arms. This happens because\n",
        "the bandit algorithm allocates most of the sample to the optimal arm(s),\n",
        "neglecting the others.\n",
        "\n",
        "We demonstrate this with an experiment simulating a control arm and four\n",
        "treatment arms with ATEs of 0.1, 0.12, 0.3, and 0.32, respectively, over a\n",
        "fixed sample size of 20,000. We expect the bandit algorithm to allocate most of\n",
        "the sample to arms 3 and 4, leaving arms 1 and 2 under-powered."
      ],
      "id": "727398b7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "def reward_fn(arm: int) -> float:\n",
        "    values = {\n",
        "        0: generator.binomial(1, 0.5),  # Control arm\n",
        "        1: generator.binomial(1, 0.6),  # ATE = 0.1\n",
        "        2: generator.binomial(1, 0.62), # ATE = 0.12\n",
        "        3: generator.binomial(1, 0.8),  # ATE = 0.3\n",
        "        4: generator.binomial(1, 0.82)  # ATE = 0.32\n",
        "    }\n",
        "    return values[arm]\n",
        "\n",
        "exp_complex = MAD(\n",
        "    bandit=TSBernoulli(k=5, control=0, reward=reward_fn),\n",
        "    alpha=0.05,\n",
        "    delta=lambda x: 1./(x**0.24),\n",
        "    t_star=int(20e3)\n",
        ")\n",
        "exp_complex.fit(early_stopping=False, verbose=False)\n",
        "\n",
        "ates = pd.concat(\n",
        "    [\n",
        "        exp_complex.estimates().assign(which=\"mad\"),\n",
        "        pd.DataFrame({\n",
        "            \"arm\": list(range(1, 5)),\n",
        "            \"ate\": [0.1, 0.12, 0.3, 0.32],\n",
        "            \"which\": [\"truth\"]*(4)\n",
        "        })\n",
        "    ],\n",
        "    axis=0\n",
        ")\n",
        "(\n",
        "    pn.ggplot(\n",
        "        ates,\n",
        "        mapping=pn.aes(\n",
        "            x=\"factor(arm)\",\n",
        "            y=\"ate\",\n",
        "            ymin=\"lb\",\n",
        "            ymax=\"ub\",\n",
        "            color=\"which\"\n",
        "        )\n",
        "    )\n",
        "    + pn.geom_point(position=pn.position_dodge(width=0.3))\n",
        "    + pn.geom_errorbar(position=pn.position_dodge(width=0.3), width=0.001)\n",
        "    + pn.geom_hline(yintercept=0, linetype=\"dashed\", color=\"black\")\n",
        "    + pn.theme_538()\n",
        "    + pn.labs(x=\"Arm\", y=\"ATE\", color=\"Method\")\n",
        ")"
      ],
      "id": "952d9ae0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As anticipated, we observe strong ATE estimates for arms 3 and 4 but\n",
        "under-powered estimates for arms 1 and 2 (CSs include 0). We can confirm that,\n",
        "indeed, TS focuses the majority of the sample on arms 3 and 4 to the detriment\n",
        "of power in our experiment."
      ],
      "id": "2bc922bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "exp_complex.plot_n()"
      ],
      "id": "1af43789",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MAD modified\n",
        "\n",
        "I propose an extension of the MAD algorithm to address the challenge of\n",
        "inadequate power in sub-optimal arms. For each treatment arm $k \\in K$\n",
        "and time period $t$, I introduce importance weights $w_{tk} \\in [0, 1]$. Once \n",
        "the estimated ATE for arm $k$ becomes statistically significant, $w_{tk}$\n",
        "begins to shrink toward zero according to a user-defined function of $t$.\n",
        "\n",
        "In the notation of Liang and Bojinov, let $A$ represent an arbitrary adaptive\n",
        "algorithm. They define $p_t^A(k)$ as the assignment probability for arm $k$ at\n",
        "time $t$ under $A$. By construction, the set $p_t^A(k)$ of\n",
        "adaptive assignment probabilities for all $k \\in K$ forms a valid probability\n",
        "distribution over $K$, meaning $\\sum_{k \\in K}{p_t^A(k)}=1$. I modify these \n",
        "probabilities to $g(p_t^A(k))$ where $g$ re-weights $p_t^A(k)$ based on the\n",
        "importance weight $w_{tk}$.\n",
        "\n",
        "For each treatment arm $k \\in K$ at time $t$, the re-weighted probability\n",
        "$g(p_t^A(k))$ is computed as follows:\n",
        "\n",
        "1.) **Apply Importance Weights**:\n",
        "Each probability is first scaled by its importance weight:\n",
        "$$p_t^*(k)=w_{tk}*p_t^A(k).$$\n",
        "\n",
        "2.) **Compute Lost Probability Mass**:\n",
        "The probability mass lost due to down-weighting is:\n",
        "$$L_t = \\sum_{k \\in K}{p_t^A(k)*(1 - w_{tk})}.$$\n",
        "\n",
        "3.) **Compute Relative Redistribution Weights**:\n",
        "The total weight sum is: $$W_t = \\sum_{k \\in K}{w_{tk}}.$$ Each arm's share of\n",
        "    the remaining mass is: $$r_{tk} = \\frac{w_{tk}}{W_t}.$$\n",
        "\n",
        "4.) **Redistribute Lost Mass**: Redistribute the lost mass proportionally to\n",
        "the relative weights: $$p_t^g(k) = p_t^*(k) + (r_{tk} * L_t).$$\n",
        "\n",
        "5.) **Normalization Check**: Since $p_t^g(k)$ for all $k \\in K$ forms\n",
        "a valid probability distribution over $K$, it satisfies: $$\\sum_{k \\in K}p_t^g(k)=1.$$\n",
        "\n",
        "Thus, the function $g$ modifies the original assignment probabilities by\n",
        "scaling each by its importance weight and redistributing the lost probability\n",
        "mass in a manner that preserves the total probability sum.\n",
        "\n",
        "### User-Specified Decay of Importance Weights\n",
        "\n",
        "The importance weight function $w_{tk}$​ controls how quickly the assignment\n",
        "probability for arm $k$ shrinks once its estimated ATE becomes statistically\n",
        "significant. This user-defined function balances two extremes:\n",
        "\n",
        "- $w_{tk}=1$ for all $t$, which keeps $g(p_t^A(k))=p_t^A(k)$, making the\n",
        "algorithm identical to the original MAD design.\n",
        "- $w_{tk}=0$ after arm $k$ reaches statistical significance,\n",
        "redirecting all future probability mass away from arm $k$ and prioritizing\n",
        "underpowered arms.\n",
        "- More generally, the user defines $w_{tk}$ somewhere in between, where:\n",
        "    - A slower decay of $w_{tk}$ (closer to 1) retains more influence from the\n",
        "    adaptive algorithm’s assignment probabilities.\n",
        "    - A faster decay (closer to 0) shifts the algorithm toward prioritizing\n",
        "    underpowered arms at the expense of bandit goals\n",
        "    (e.g. reward maximization).\n",
        "\n",
        "Reasonable choices for $w_{tk}$ include polynomial or exponential decay,\n",
        "providing flexibility in tuning sample reallocation.\n",
        "\n",
        "## Algorithm comparison\n",
        "\n",
        "I compare the two algorithms to highlight the benefits of the modified\n",
        "approach. The modified algorithm significantly improves power to detect\n",
        "non-zero ATEs in all treatment arms and provides more precise ATE estimates\n",
        "than the original MAD algorithm with the same sample size. However, this comes\n",
        "at the cost of assigning more sample to sub-optimal arms, where \"optimal\" is\n",
        "defined by the underlying bandit algorithm.\n",
        "\n",
        "### Improved power and precision\n",
        "\n",
        "The following plots demonstrate the increased power and precision of the\n",
        "modified MAD algorithm."
      ],
      "id": "4d3c4ea5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "# Run the modified algorithm\n",
        "mad_modified = MADModified(\n",
        "    bandit=TSBernoulli(k=5, control=0, reward=reward_fn),\n",
        "    alpha=0.05,\n",
        "    delta=lambda x: 1./(x**0.24),\n",
        "    t_star=int(20e3),\n",
        "    decay=lambda x: 1./(x**(1./8.))\n",
        ")\n",
        "mad_modified.fit(cs_precision=0.1, verbose=False, early_stopping=True)\n",
        "\n",
        "# Run the vanilla algorithm\n",
        "mad_vanilla = MAD(\n",
        "    bandit=TSBernoulli(k=5, control=0, reward=reward_fn),\n",
        "    alpha=0.05,\n",
        "    delta=lambda x: 1./(x**0.24),\n",
        "    t_star=mad_modified._bandit._t\n",
        ")\n",
        "mad_vanilla.fit(verbose=False, early_stopping=False)\n",
        "\n",
        "# Compare the ATEs and CSs\n",
        "ates = pd.concat(\n",
        "    [\n",
        "        mad_modified.estimates().assign(which=\"MADMod\"),\n",
        "        mad_vanilla.estimates().assign(which=\"MAD\"),\n",
        "        pd.DataFrame({\n",
        "            \"arm\": list(range(1, 5)),\n",
        "            \"ate\": [0.1, 0.12, 0.3, 0.32],\n",
        "            \"which\": [\"Truth\"]*(4)\n",
        "        })\n",
        "    ],\n",
        "    axis=0\n",
        ")\n",
        "(\n",
        "    pn.ggplot(\n",
        "        ates,\n",
        "        mapping=pn.aes(\n",
        "            x=\"factor(arm)\",\n",
        "            y=\"ate\",\n",
        "            ymin=\"lb\",\n",
        "            ymax=\"ub\",\n",
        "            color=\"which\"\n",
        "        )\n",
        "    )\n",
        "    + pn.geom_point(position=pn.position_dodge(width=0.3))\n",
        "    + pn.geom_errorbar(position=pn.position_dodge(width=0.3), width=0.001)\n",
        "    + pn.geom_hline(yintercept=0, linetype=\"dashed\", color=\"black\")\n",
        "    + pn.theme_538()\n",
        "    + pn.labs(x=\"Arm\", y=\"ATE\", color=\"Method\")\n",
        ")"
      ],
      "id": "f4510e2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the following plot compares the sample assignment to the treatment arms\n",
        "of the two algorithms:"
      ],
      "id": "66e0fc69"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "sample_sizes = pd.concat([\n",
        "    pd.DataFrame(x) for x in\n",
        "    [\n",
        "        {\n",
        "            \"arm\": [k for k in range(len(mad_modified._ate))],\n",
        "            \"n\": [last(n) for n in mad_modified._n],\n",
        "            \"which\": [\"MADMod\"]*len(mad_modified._ate)\n",
        "        },\n",
        "        {\n",
        "            \"arm\": [k for k in range(len(mad_vanilla._ate))],\n",
        "            \"n\": [last(n) for n in mad_vanilla._n],\n",
        "            \"which\": [\"MAD\"]*len(mad_vanilla._ate)\n",
        "        }\n",
        "    ]\n",
        "])\n",
        "(\n",
        "    pn.ggplot(sample_sizes, pn.aes(x=\"factor(arm)\", y=\"n\", fill=\"which\", color=\"which\"))\n",
        "    + pn.geom_bar(stat=\"identity\", position=pn.position_dodge(width=0.75), width=0.7)\n",
        "    + pn.theme_538()\n",
        "    + pn.labs(x=\"Arm\", y=\"N\", color=\"Method\", fill=\"Method\")\n",
        ")"
      ],
      "id": "73608f43",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simulation results over 1,0000 runs\n",
        "\n",
        "We can more precisely quantify the improvements by running 1,000 simulations,\n",
        "comparing Type 2 error and confidence band width between the vanilla MAD\n",
        "algorithm and the modified algorithm. Each simulation runs for 20,000\n",
        "iterations with early stopping. If the modified algorithm stops early, the\n",
        "vanilla algorithm will also stop early to maintain equal sample sizes in each\n",
        "simulation."
      ],
      "id": "600daf9c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "def delta_fn(x):\n",
        "    return 1. / (x ** 0.24)\n",
        "\n",
        "def decay_fn(x):\n",
        "    return 1. / (x ** (1. / 8.))\n",
        "\n",
        "def compare(i):\n",
        "    mad_modified = MADModified(\n",
        "        bandit=TSBernoulli(k=5, control=0, reward=reward_fn),\n",
        "        alpha=0.05,\n",
        "        delta=delta_fn,\n",
        "        t_star=int(2e4),\n",
        "        decay=decay_fn\n",
        "    )\n",
        "    mad_modified.fit(cs_precision=0.1, verbose=False, early_stopping=True)\n",
        "\n",
        "    # Run the vanilla algorithm\n",
        "    mad_vanilla = MAD(\n",
        "        bandit=TSBernoulli(k=5, control=0, reward=reward_fn),\n",
        "        alpha=0.05,\n",
        "        delta=delta_fn,\n",
        "        t_star=mad_modified._bandit._t\n",
        "    )\n",
        "    mad_vanilla.fit(verbose=False, early_stopping=False)\n",
        "\n",
        "    # Calculate the Type 2 error and the Confidence Sequence width\n",
        "\n",
        "    ## For modified algorithm\n",
        "    mad_mod_n = (\n",
        "        pd\n",
        "        .DataFrame([\n",
        "            {\"arm\": k, \"n\": last(mad_modified._n[k])}\n",
        "            for k in range(mad_modified._bandit.k())\n",
        "            if k != mad_modified._bandit.control()\n",
        "        ])\n",
        "        .assign(\n",
        "            n_pct=lambda x: x[\"n\"].apply(lambda y: y/np.sum(x[\"n\"]))\n",
        "        )\n",
        "    )\n",
        "    mad_mod_df = (\n",
        "        mad_modified\n",
        "        .estimates()\n",
        "        .assign(\n",
        "            idx=i,\n",
        "            method=\"modified\",\n",
        "            width=lambda x: x[\"ub\"] - x[\"lb\"],\n",
        "            error=lambda x: ((0 > x[\"lb\"]) & (0 < x[\"ub\"]))\n",
        "        )\n",
        "        .merge(mad_mod_n, on=\"arm\", how=\"left\")\n",
        "    )\n",
        "\n",
        "    ## For vanilla algorithm\n",
        "    mad_van_n = (\n",
        "        pd\n",
        "        .DataFrame([\n",
        "            {\"arm\": k, \"n\": last(mad_vanilla._n[k])}\n",
        "            for k in range(mad_vanilla._bandit.k())\n",
        "            if k != mad_vanilla._bandit.control()\n",
        "        ])\n",
        "        .assign(\n",
        "            n_pct=lambda x: x[\"n\"].apply(lambda y: y/np.sum(x[\"n\"]))\n",
        "        )\n",
        "    )\n",
        "    mad_van_df = (\n",
        "        mad_vanilla\n",
        "        .estimates()\n",
        "        .assign(\n",
        "            idx=i,\n",
        "            method=\"mad\",\n",
        "            width=lambda x: x[\"ub\"] - x[\"lb\"],\n",
        "            error=lambda x: ((0 > x[\"lb\"]) & (0 < x[\"ub\"]))\n",
        "        )\n",
        "        .merge(mad_van_n, on=\"arm\", how=\"left\")\n",
        "    )\n",
        "\n",
        "    out = {\n",
        "        \"metrics\": pd.concat([mad_mod_df, mad_van_df]),\n",
        "        \"reward\": {\n",
        "            \"modified\": np.sum(mad_modified._rewards),\n",
        "            \"mad\": np.sum(mad_vanilla._rewards)\n",
        "        }\n",
        "    }\n",
        "    return out\n",
        "\n",
        "# Execute in parallel with joblib\n",
        "comparison_results_list = [\n",
        "    x for x in\n",
        "    joblib.Parallel(return_as=\"generator\", n_jobs=-1)(\n",
        "        joblib.delayed(compare)(i) for i in range(100)\n",
        "    )\n",
        "]\n",
        "\n",
        "# Compare performance on key metrics across simulations\n",
        "metrics_df = pd.melt(\n",
        "    (\n",
        "        pd\n",
        "        .concat([x[\"metrics\"] for x in comparison_results_list])\n",
        "        .reset_index(drop=True)\n",
        "        .assign(error=lambda x: x[\"error\"].apply(lambda y: int(y)))\n",
        "    ),\n",
        "    id_vars=[\"arm\", \"method\"],\n",
        "    value_vars=[\"width\", \"error\", \"n\", \"n_pct\"],\n",
        "    var_name=\"meas\",\n",
        "    value_name=\"value\"\n",
        ")\n",
        "\n",
        "# Compare reward accumulation across simulations\n",
        "reward_df = pd.melt(\n",
        "    pd.DataFrame([x[\"reward\"] for x in comparison_results_list]),\n",
        "    value_vars=[\"modified\", \"mad\"],\n",
        "    var_name=\"method\",\n",
        "    value_name=\"reward\"\n",
        ")\n",
        "\n",
        "metrics_summary = (\n",
        "    metrics_df\n",
        "    .groupby([\"arm\", \"method\", \"meas\"], as_index=False).agg(\n",
        "        mean=(\"value\", \"mean\"),\n",
        "        std=(\"value\", \"std\"),\n",
        "        n=(\"value\", \"count\")\n",
        "    )\n",
        "    .assign(\n",
        "        se=lambda x: x[\"std\"] / np.sqrt(x[\"n\"]),\n",
        "        t_val=lambda x: t.ppf(0.975, x[\"n\"] - 1),\n",
        "        ub=lambda x: x[\"mean\"] + x[\"t_val\"] * x[\"se\"],\n",
        "        lb=lambda x: x[\"mean\"] - x[\"t_val\"] * x[\"se\"]\n",
        "    )\n",
        "    .drop(columns=[\"se\", \"t_val\"])\n",
        ")"
      ],
      "id": "185d30f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following plot shows the mean (and 95% confidence intervals) of the Type 2\n",
        "error and CS width for both algorithms."
      ],
      "id": "1887ecf2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "facet_labels = {\n",
        "    \"error\": \"Type 2 error\",\n",
        "    \"width\": \"Interval width\",\n",
        "    \"n\": \"Sample size\",\n",
        "    \"n_pct\": \"Sample size %\"\n",
        "}\n",
        "(\n",
        "    pn.ggplot(\n",
        "        metrics_summary[metrics_summary[\"meas\"].isin([\"error\", \"width\"])],\n",
        "        pn.aes(\n",
        "            x=\"factor(arm)\",\n",
        "            y=\"mean\",\n",
        "            ymin=\"lb\",\n",
        "            ymax=\"ub\",\n",
        "            color=\"method\"\n",
        "        )\n",
        "    )\n",
        "    + pn.geom_point(position=pn.position_dodge(width=0.2))\n",
        "    + pn.geom_errorbar(position=pn.position_dodge(width=0.2), width=0.01)\n",
        "    + pn.facet_wrap(\n",
        "        \"~ meas\",\n",
        "        labeller=lambda x: facet_labels[x],\n",
        "        scales=\"free\"\n",
        "    )\n",
        "    + pn.theme_538()\n",
        "    + pn.labs(x=\"Arm\", y=\"\", color=\"Method\")\n",
        ")"
      ],
      "id": "f0b0c832",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The modified MAD algorithm achieves far lower Type 2 error and improved\n",
        "ATE precision in all treatment arms.\n",
        "\n",
        "### Tradeoffs\n",
        "\n",
        "These plots illustrate the tradeoffs of the modified algorithm. On average,\n",
        "it allocates significantly more sample to sub-optimal arms compared to the\n",
        "standard MAD algorithm."
      ],
      "id": "16bbcc6f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "(\n",
        "    pn.ggplot(\n",
        "        metrics_summary[metrics_summary[\"meas\"].isin([\"n\", \"n_pct\"])],\n",
        "        pn.aes(\n",
        "            x=\"factor(arm)\",\n",
        "            y=\"mean\",\n",
        "            ymin=\"lb\",\n",
        "            ymax=\"ub\",\n",
        "            color=\"method\"\n",
        "        )\n",
        "    )\n",
        "    + pn.geom_point(position=pn.position_dodge(width=0.2))\n",
        "    + pn.geom_errorbar(position=pn.position_dodge(width=0.2), width=0.01)\n",
        "    + pn.facet_wrap(\n",
        "        \"~ meas\",\n",
        "        labeller=lambda x: facet_labels[x],\n",
        "        scales=\"free\"\n",
        "    )\n",
        "    + pn.theme_538()\n",
        "    + pn.labs(x=\"Arm\", y=\"\", color=\"Method\")\n",
        ")"
      ],
      "id": "d4655ecb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a result, this reallocation reduces total reward accumulation. The\n",
        "difference in accumulated reward across the 1,000 simulations is shown below:"
      ],
      "id": "234dd2c1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "(\n",
        "    pn.ggplot(reward_df, pn.aes(x=\"method\", y=\"reward\"))\n",
        "    + pn.geom_boxplot()\n",
        "    + pn.theme_538()\n",
        "    + pn.labs(x=\"Method\", y=\"Cumulative reward\")\n",
        ")"
      ],
      "id": "aea5c694",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In summary, this approach allows us to achieve\n",
        "**anytime-valid inference on the ATE**, enabling early stopping for greater\n",
        "flexibility and efficiency. It also allows us to\n",
        "**ensure dynamic sample allocation**, guaranteeing sufficient power for all\n",
        "(or the top n) treatment arms."
      ],
      "id": "d95bec9d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}