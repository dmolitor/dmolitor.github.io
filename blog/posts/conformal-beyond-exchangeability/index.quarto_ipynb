{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Conformal Prediction Beyond Exchangeability\"\n",
        "description: |\n",
        "  Replicating empirical examples from <a href=\"https://projecteuclid.org/journals/annals-of-statistics/volume-51/issue-2/Conformal-prediction-beyond-exchangeability/10.1214/23-AOS2276.full\">Conformal Prediction Beyond Exchangeability\n",
        "  by Barber, et al.</a>\n",
        "date: \"7/25/2024\"\n",
        "format:\n",
        "  html:\n",
        "    toc: false\n",
        "    toc-location: right\n",
        "    code-overflow: scroll\n",
        "execute: \n",
        "  freeze: true\n",
        "page-layout: full\n",
        "categories: [Conformal Prediction]\n",
        "image: \"./thumbnail.jpg\"\n",
        "---\n",
        "\n",
        "\n",
        "### Dependencies\n"
      ],
      "id": "cfb3a23e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "#| error: false\n",
        "#| echo: true\n",
        "\n",
        "from great_tables import GT, md\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import plotnine as pn\n",
        "import statsmodels.api as sm\n",
        "from tqdm import tqdm\n",
        "from typing import Any, Callable, List\n",
        "\n",
        "base_dir = Path().cwd()\n",
        "generator = np.random.default_rng()"
      ],
      "id": "d8dc250f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data\n"
      ],
      "id": "ee8e7f77"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "#| error: false\n",
        "#| echo: true\n",
        "\n",
        "# Electricity data\n",
        "electricity = pd.read_csv(base_dir / \"data\" / \"electricity-normalized.csv\")\n",
        "electricity = (\n",
        "    electricity\n",
        "    .iloc[17760:]\n",
        "    .assign(period=lambda x: x.period*24)\n",
        "    .loc[lambda df: (df[\"period\"] >= 9) & (df[\"period\"] <= 12)]\n",
        "    [[\"transfer\", \"nswprice\", \"vicprice\", \"nswdemand\", \"vicdemand\"]]\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "permuted = electricity.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Function to generate simulated data\n",
        "def sim_data(N: int, d: int, setting: int) -> tuple[pd.DataFrame, npt.NDArray]:\n",
        "    X = np.random.multivariate_normal(mean=np.zeros(d), cov=np.eye(d), size=N)\n",
        "    if setting == 1:\n",
        "        beta = np.array([2, 1, 0, 0])\n",
        "        y = X @ beta + np.random.normal(0, 1, N)\n",
        "        X = pd.DataFrame(X, columns=[f\"feature_{i+1}\" for i in range(d)])\n",
        "    elif setting == 2:\n",
        "        beta_1 = np.array([2, 1, 0, 0])\n",
        "        beta_2 = np.array([0, -2, -1, 0])\n",
        "        beta_3 = np.array([0, 0, 2, 1])\n",
        "        y = np.zeros(N)\n",
        "        # Generate y for different segments\n",
        "        y[:500] = X[:500] @ beta_1 + np.random.normal(0, 1, 500)\n",
        "        y[500:1500] = X[500:1500] @ beta_2 + np.random.normal(0, 1, 1000)\n",
        "        y[1500:] = X[1500:] @ beta_3 + np.random.normal(0, 1, 500)\n",
        "        X = pd.DataFrame(X, columns=[f\"feature_{i+1}\" for i in range(d)])\n",
        "    else:\n",
        "        beta_start = np.array([2, 1, 0, 0])\n",
        "        beta_end = np.array([0, 0, 2, 1])\n",
        "        beta = np.linspace(beta_start, beta_end, N)\n",
        "        y = np.array([X[i] @ beta[i] + np.random.normal(0, 1) for i in range(N)])\n",
        "        X = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(d)])\n",
        "    return (X, y)"
      ],
      "id": "0255c91b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions\n",
        "\n",
        "The `nexcp_split` function implements non-exchangeable split conformal prediction (CP).\n",
        "However, we can force it to also implement standard CP,\n",
        "which assumes exchangeability, by setting uniform weights. So we only need one \n",
        "function to replicate the results!\n"
      ],
      "id": "6af771bc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "#| error: false\n",
        "#| echo: true\n",
        "\n",
        "def normalize_weights(weights: npt.NDArray):\n",
        "    return weights / weights.sum()\n",
        "\n",
        "\n",
        "def nexcp_split(\n",
        "    model: Callable[[npt.NDArray, pd.DataFrame, npt.NDArray], Any],\n",
        "    split_function: Callable[[int], npt.NDArray],\n",
        "    y: npt.NDArray,\n",
        "    X: pd.DataFrame,\n",
        "    tag_function: Callable[[int], npt.NDArray],\n",
        "    weight_function: Callable[[int], npt.NDArray],\n",
        "    alpha: float,\n",
        "    test_index: int\n",
        "):\n",
        "    \"\"\"Implements non-exchangeable split conformal prediction\"\"\"\n",
        "    \n",
        "    # Pull test observation from data\n",
        "    y_test = y[test_index]\n",
        "    X_test = X.iloc[[test_index]]\n",
        "    # Select all observations up to that point\n",
        "    y = y[:test_index]\n",
        "    X = X.iloc[:test_index]\n",
        "    # Generate indices for train/calibration split\n",
        "    split_indices = split_function(test_index)\n",
        "    # Split data, tags, and weights\n",
        "    X_train = X.iloc[split_indices]\n",
        "    y_train = y[split_indices]\n",
        "    X_calib = X.drop(split_indices)\n",
        "    y_calib = np.delete(y, split_indices)\n",
        "    # Generate tags and weights\n",
        "    tags = tag_function(test_index)\n",
        "    weights = weight_function(test_index)\n",
        "    # Train model\n",
        "    model_base = model(y_train, X_train, weights=tags[split_indices])\n",
        "    model_fitted = model_base.fit()\n",
        "    # Generate residuals\n",
        "    residuals = np.abs(y_calib - model_fitted.predict(X_calib))\n",
        "    # Calculate weighted quantile of residuals\n",
        "    weights_calib = normalize_weights(np.delete(weights[:test_index], split_indices))\n",
        "    q_hat = np.quantile(\n",
        "        residuals,\n",
        "        1 - alpha,\n",
        "        weights=weights_calib,\n",
        "        method=\"inverted_cdf\"\n",
        "    )\n",
        "    # Calculate predicted value\n",
        "    y_hat = model_fitted.predict(X_test).iloc[0]\n",
        "    # Generate CI\n",
        "    lb = y_hat - q_hat\n",
        "    ub = y_hat + q_hat\n",
        "    covered = lb <= y_test <= ub\n",
        "    return {\"ci\": np.array([lb, y_hat, ub]), \"covered\": covered, \"width\": ub-lb}\n",
        "\n",
        "\n",
        "def plot_rolling_coverage(\n",
        "    results: List[dict],\n",
        "    alpha: float = 0.1,\n",
        "    window: int = 300,\n",
        "    rows: int = 2,\n",
        "    repeated: bool = False\n",
        "):\n",
        "    \"\"\"Plot the algorithm's mean coverage over a sliding window\"\"\"\n",
        "\n",
        "    coverage_df = pd.DataFrame(results)\n",
        "    if repeated:\n",
        "        coverage_df = (\n",
        "            coverage_df\n",
        "            .groupby([\"method\", \"dataset\", \"index\"])[\"covered\"]\n",
        "            .mean()\n",
        "            .reset_index()\n",
        "        )\n",
        "    coverage_df[\"coverage_mean\"] = (\n",
        "        coverage_df\n",
        "        .groupby([\"method\", \"dataset\"])[\"covered\"]\n",
        "        .transform(lambda x: x.rolling(window=window).mean())\n",
        "    )\n",
        "    coverage_df[\"time\"] = coverage_df.groupby([\"method\", \"dataset\"]).cumcount() + 1\n",
        "    coverage_df = coverage_df.dropna(subset=[\"coverage_mean\"])\n",
        "    coverage_plot = (\n",
        "        pn.ggplot(\n",
        "            coverage_df,\n",
        "            pn.aes(x=\"time\", y=\"coverage_mean\", color=\"method\", group=\"method\")\n",
        "        )\n",
        "        + pn.geom_line()\n",
        "        + pn.geom_hline(yintercept=1-alpha, linetype=\"solid\")\n",
        "        + pn.scale_y_continuous(limits=(0, 1))\n",
        "        + pn.facet_wrap(\"~ dataset\", nrow=rows, scales=\"free\")\n",
        "        + pn.theme_538()\n",
        "        + pn.labs(x=\"Time\", y=\"Coverage\", color=\"Method\")\n",
        "    )\n",
        "    return coverage_plot\n",
        "\n",
        "\n",
        "def plot_rolling_width(\n",
        "    results: dict,\n",
        "    window: int = 300,\n",
        "    rows: int = 2,\n",
        "    repeated: bool = False\n",
        "):\n",
        "    \"\"\"Plot the algorithm's mean prediction interval width over a sliding window\"\"\"\n",
        "\n",
        "    width_df = pd.DataFrame(results)\n",
        "    if repeated:\n",
        "        width_df = (\n",
        "            width_df\n",
        "            .groupby([\"method\", \"dataset\", \"index\"])[\"width\"]\n",
        "            .mean()\n",
        "            .reset_index()\n",
        "        )\n",
        "    width_df[\"width_mean\"] = (\n",
        "        width_df\n",
        "        .groupby([\"method\", \"dataset\"])[\"width\"]\n",
        "        .transform(lambda x: x.rolling(window=window).mean())\n",
        "    )\n",
        "    width_df[\"time\"] = width_df.groupby([\"method\", \"dataset\"]).cumcount() + 1\n",
        "    width_df = width_df.dropna(subset=[\"width_mean\"])\n",
        "    width_plot = (\n",
        "        pn.ggplot(\n",
        "            width_df,\n",
        "            pn.aes(x=\"time\", y=\"width_mean\", color=\"method\", group=\"method\")\n",
        "        )\n",
        "        + pn.geom_line()\n",
        "        + pn.facet_wrap(\"~ dataset\", nrow=rows, scales=\"free\")\n",
        "        + pn.theme_538()\n",
        "        + pn.labs(x=\"Time\", y=\"Width\", color=\"Method\")\n",
        "    )\n",
        "    return width_plot"
      ],
      "id": "c65b022c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Electricity example\n",
        "\n",
        "Note: I implement non-exchangeable split CP with least-squares by using WLS and setting\n",
        "all the tags to a uniform value. Standard CP is implemented by setting all the weights\n",
        "to a uniform value as mentioned above.\n"
      ],
      "id": "a91479f3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "#| error: false\n",
        "#| echo: true\n",
        "\n",
        "split_fn = lambda x: np.sort(generator.choice(x, int(np.floor(x*0.3)), replace=False))\n",
        "results = []\n",
        "\n",
        "# Create X and y for the normal and permuted data\n",
        "X, y = (electricity.drop(\"transfer\", axis=1), electricity[\"transfer\"].to_numpy())\n",
        "X_perm, y_perm = (permuted.drop(\"transfer\", axis=1), permuted[\"transfer\"].to_numpy())\n",
        "\n",
        "# Predict for each observation from N=100 to N=len(electricity)\n",
        "for i in tqdm(range(100, len(electricity)), total=len(electricity)-100):\n",
        "    for method in [\"NexCP+LS\", \"NexCP+WLS\", \"CP+LS\"]:\n",
        "        for dataset in [\"Electricity\", \"Permuted\"]:\n",
        "            if dataset == \"Electricity\":\n",
        "                X_model, y_model = (X, y)\n",
        "            else:\n",
        "                X_model, y_model = (X_perm, y_perm)\n",
        "            if method == \"NexCP+LS\":\n",
        "                tag_fn = lambda x: np.array([1.]*(x + 1))\n",
        "                weight_fn = lambda x: 0.99**np.arange(x, -1, -1)\n",
        "            elif method == \"NexCP+WLS\":\n",
        "                tag_fn = lambda x: 0.99**np.arange(x, -1, -1)\n",
        "                weight_fn = tag_fn\n",
        "            else:\n",
        "                tag_fn = lambda x: np.array([1.]*(x + 1))\n",
        "                weight_fn = tag_fn\n",
        "            out = nexcp_split(\n",
        "                model=sm.WLS,\n",
        "                split_function=split_fn,\n",
        "                y=y_model,\n",
        "                X=X_model,\n",
        "                tag_function=tag_fn,\n",
        "                weight_function=weight_fn,\n",
        "                alpha=0.1,\n",
        "                test_index=i\n",
        "            )\n",
        "            out[\"method\"] = method\n",
        "            out[\"dataset\"] = dataset\n",
        "            out[\"index\"] = i\n",
        "            del out[\"ci\"]\n",
        "            results.append(out)"
      ],
      "id": "87a84e18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plots\n"
      ],
      "id": "1f890e15"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "#| error: false\n",
        "#| echo: true\n",
        "#| fig-align: center\n",
        "#| layout-ncol: 2\n",
        "\n",
        "coverage_plot = plot_rolling_coverage(results, alpha=0.1, window=300)\n",
        "coverage_plot.show()\n",
        "\n",
        "width_plot = plot_rolling_width(results, window=300)\n",
        "width_plot.show()"
      ],
      "id": "519ade1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Table\n"
      ],
      "id": "6a51d29c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "#| error: false\n",
        "#| echo: true\n",
        "\n",
        "table = (\n",
        "    pd\n",
        "    .DataFrame(results)\n",
        "    .groupby([\"method\", \"dataset\"])\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "table = (\n",
        "    table\n",
        "    .pivot_table(\n",
        "        index='method',\n",
        "        columns='dataset',\n",
        "        values=['covered', 'width']\n",
        "    )\n",
        ")\n",
        "table.columns = [f'{col[0]}_{col[1].lower()}' for col in table.columns]\n",
        "table = table.reset_index()\n",
        "table = (\n",
        "    GT(table, rowname_col=\"method\")\n",
        "    .tab_spanner(\n",
        "        label=\"Electricity data\",\n",
        "        columns=[\"covered_electricity\", \"width_electricity\"]\n",
        "    )\n",
        "    .tab_spanner(\n",
        "        label=\"Permuted electricity data\",\n",
        "        columns=[\"covered_permuted\", \"width_permuted\"]\n",
        "    )\n",
        "    .fmt_number(\n",
        "        columns = [\n",
        "            \"covered_electricity\",\n",
        "            \"width_electricity\",\n",
        "            \"covered_permuted\",\n",
        "            \"width_permuted\"\n",
        "        ],\n",
        "        decimals=3\n",
        "    )\n",
        "    .cols_label(\n",
        "        covered_electricity = \"Coverage\",\n",
        "        width_electricity = \"Width\",\n",
        "        covered_permuted = \"Coverage\",\n",
        "        width_permuted = \"Width\"\n",
        "    )\n",
        ")\n",
        "table.show()"
      ],
      "id": "31e65fa4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simulated example\n",
        "\n",
        "This demonstrates the conformal prediction algorithm in the following data settings:\n",
        "i.i.d. data, data generating process with changepoints, and data with distribution drift.\n",
        "In the paper they repeat this 200 times to smooth the estimates, but for computational\n",
        "purposes here I only repeated it 50 times.\n"
      ],
      "id": "6e3b2bf4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "#| error: false\n",
        "#| echo: true\n",
        "split_fn = lambda x: np.sort(generator.choice(x, int(np.floor(x*0.3)), replace=False))\n",
        "results = []\n",
        "\n",
        "# Predict for each observation from N=100 to N=len(electricity)\n",
        "for i in tqdm(range(100, 2000), total=2000-100):\n",
        "    for rep in range(50):\n",
        "        for method in [\"NexCP+LS\", \"NexCP+WLS\", \"CP+LS\"]:\n",
        "            for dataset in [\"setting_1\", \"setting_2\", \"setting_3\"]:\n",
        "                if dataset == \"setting_1\":\n",
        "                    X_model, y_model = sim_data(2000, 4, setting=1)\n",
        "                elif dataset == \"setting_2\":\n",
        "                    X_model, y_model = sim_data(2000, 4, setting=2)\n",
        "                else:\n",
        "                    X_model, y_model = sim_data(2000, 4, setting=3)\n",
        "                if method == \"NexCP+LS\":\n",
        "                    tag_fn = lambda x: np.array([1.]*(x + 1))\n",
        "                    weight_fn = lambda x: 0.99**np.arange(x, -1, -1)\n",
        "                elif method == \"NexCP+WLS\":\n",
        "                    tag_fn = lambda x: 0.99**np.arange(x, -1, -1)\n",
        "                    weight_fn = tag_fn\n",
        "                else:\n",
        "                    tag_fn = lambda x: np.array([1.]*(x + 1))\n",
        "                    weight_fn = tag_fn\n",
        "                out = nexcp_split(\n",
        "                    model=sm.WLS,\n",
        "                    split_function=split_fn,\n",
        "                    y=y_model,\n",
        "                    X=X_model,\n",
        "                    tag_function=tag_fn,\n",
        "                    weight_function=weight_fn,\n",
        "                    alpha=0.1,\n",
        "                    test_index=i\n",
        "                )\n",
        "                out[\"method\"] = method\n",
        "                out[\"dataset\"] = dataset\n",
        "                out[\"index\"] = i\n",
        "                del out[\"ci\"]\n",
        "                results.append(out)"
      ],
      "id": "a8bbbf6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plots\n"
      ],
      "id": "c6a967e9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "#| error: false\n",
        "#| echo: true\n",
        "#| fig-align: center\n",
        "#| layout-ncol: 2\n",
        "\n",
        "coverage_plot = plot_rolling_coverage(\n",
        "    results,\n",
        "    alpha=0.1,\n",
        "    window=10,\n",
        "    rows=3,\n",
        "    repeated=True\n",
        ")\n",
        "coverage_plot.show()\n",
        "\n",
        "width_plot = plot_rolling_width(results, window=10, rows=3, repeated=True)\n",
        "width_plot.show()"
      ],
      "id": "4ce26264",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Table\n"
      ],
      "id": "fc361b93"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| warning: false\n",
        "#| error: false\n",
        "#| echo: true\n",
        "\n",
        "table = (\n",
        "    pd\n",
        "    .DataFrame(results)\n",
        "    .groupby([\"method\", \"dataset\", \"index\"])\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .drop(labels=[\"index\"], axis=1)\n",
        "    .groupby([\"method\", \"dataset\"])\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "table = (\n",
        "    table\n",
        "    .pivot_table(\n",
        "        index=\"method\",\n",
        "        columns=\"dataset\",\n",
        "        values=[\"covered\", \"width\"]\n",
        "    )\n",
        ")\n",
        "table.columns = [f\"{col[0]}_{col[1].lower()}\" for col in table.columns]\n",
        "table = table.reset_index()\n",
        "table = (\n",
        "    GT(table, rowname_col=\"method\")\n",
        "    .tab_spanner(\n",
        "        label=\"Setting 1 (i.i.d. data)\",\n",
        "        columns=[\"covered_setting_1\", \"width_setting_1\"]\n",
        "    )\n",
        "    .tab_spanner(\n",
        "        label=\"Setting 2 (changepoints)\",\n",
        "        columns=[\"covered_setting_2\", \"width_setting_2\"]\n",
        "    )\n",
        "    .tab_spanner(\n",
        "        label=\"Setting 3 (drift)\",\n",
        "        columns=[\"covered_setting_3\", \"width_setting_3\"]\n",
        "    )\n",
        "    .fmt_number(\n",
        "        columns = [\n",
        "            \"covered_setting_1\",\n",
        "            \"width_setting_1\",\n",
        "            \"covered_setting_2\",\n",
        "            \"width_setting_2\",\n",
        "            \"covered_setting_3\",\n",
        "            \"width_setting_3\"\n",
        "        ],\n",
        "        decimals=3\n",
        "    )\n",
        "    .cols_label(\n",
        "        covered_setting_1 = \"Coverage\",\n",
        "        width_setting_1 = \"Width\",\n",
        "        covered_setting_2 = \"Coverage\",\n",
        "        width_setting_2 = \"Width\",\n",
        "        covered_setting_3 = \"Coverage\",\n",
        "        width_setting_3 = \"Width\"\n",
        "    )\n",
        ")\n",
        "table.show()"
      ],
      "id": "19400caf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}