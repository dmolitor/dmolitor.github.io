<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Wowchemy 5.4.0 for Hugo">
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Lora:wght@400;700&family=Roboto:wght@400;700&display=swap&display=swap">
<link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Lora:wght@400;700&family=Roboto:wght@400;700&display=swap&display=swap" media=print onload="this.media='all'">
<meta name=author content="Daniel Molitor">
<meta name=description content="The goal of this short project is to document a fairly realistic ML pipeline, including data cleaning, data visualization, and model development, in both R and Python.">
<link rel=alternate hreflang=en-us href=https://dmolitor.com/post/2022-02-02-housing-price-prediction/>
<meta name=theme-color content="hsl(339, 90%, 68%)">
<link rel=stylesheet href=/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/atom-one-dark-reasonable.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/atom-one-dark-reasonable.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload="this.media='all'">
<link rel=stylesheet href=/css/wowchemy.ec90f5daff304f2516554c1fa6fbc308.css>
<link rel=manifest href=/manifest.webmanifest>
<link rel=icon type=image/png href=/media/icon_hucde9d3bf436934aea32678e4ee07e929_14509_32x32_fill_lanczos_center_3.png>
<link rel=apple-touch-icon type=image/png href=/media/icon_hucde9d3bf436934aea32678e4ee07e929_14509_180x180_fill_lanczos_center_3.png>
<link rel=canonical href=https://dmolitor.com/post/2022-02-02-housing-price-prediction/>
<meta property="twitter:card" content="summary_large_image">
<meta property="og:site_name" content="Daniel Molitor">
<meta property="og:url" content="https://dmolitor.com/post/2022-02-02-housing-price-prediction/">
<meta property="og:title" content="Housing Prices Prediction | Daniel Molitor">
<meta property="og:description" content="The goal of this short project is to document a fairly realistic ML pipeline, including data cleaning, data visualization, and model development, in both R and Python."><meta property="og:image" content="https://dmolitor.com/post/2022-02-02-housing-price-prediction/featured.jpg">
<meta property="twitter:image" content="https://dmolitor.com/post/2022-02-02-housing-price-prediction/featured.jpg"><meta property="og:locale" content="en-us">
<meta property="article:published_time" content="2022-02-03T00:00:00+00:00">
<meta property="article:modified_time" content="2022-02-03T00:00:00+00:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://dmolitor.com/post/2022-02-02-housing-price-prediction/"},"headline":"Housing Prices Prediction","image":["https://dmolitor.com/post/2022-02-02-housing-price-prediction/featured.jpg"],"datePublished":"2022-02-03T00:00:00Z","dateModified":"2022-02-03T00:00:00Z","author":{"@type":"Person","name":"Daniel Molitor"},"publisher":{"@type":"Organization","name":"Daniel Molitor","logo":{"@type":"ImageObject","url":"https://dmolitor.com/media/icon_hucde9d3bf436934aea32678e4ee07e929_14509_192x192_fill_lanczos_center_3.png"}},"description":"The goal of this short project is to document a fairly realistic ML pipeline, including data cleaning, data visualization, and model development, in both R and Python."}</script>
<title>Housing Prices Prediction | Daniel Molitor</title>
</head>
<body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class="page-wrapper dark" data-wc-page-id=c51f02bcdfbde40203348a1cfdc06acc>
<script src=/js/wowchemy-init.min.b0e67c88a5da645111c4840aa68f1002.js></script>
<aside class=search-modal id=search>
<div class=container>
<section class=search-header>
<div class="row no-gutters justify-content-between mb-3">
<div class=col-6>
<h1>Search</h1>
</div>
<div class="col-6 col-search-close">
<a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a>
</div>
</div>
<div id=search-box>
<input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...>
</div>
</section>
<section class=section-search-results>
<div id=search-hits>
</div>
</section>
</div>
</aside>
<div class=page-header>
<header class=header--fixed>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
<div class=container-xl>
<div class="d-none d-lg-inline-flex">
<a class=navbar-brand href=/>Daniel Molitor</a>
</div>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span>
</button>
<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
<a class=navbar-brand href=/>Daniel Molitor</a>
</div>
<div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content>
<ul class="navbar-nav d-md-inline-flex">
<li class=nav-item>
<a class="nav-link active" href=/post><span>Musings</span></a>
</li>
</ul>
</div>
<ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
</ul>
</div>
</nav>
</header>
</div>
<div class=page-body>
<article class=article>
<div class="article-container pt-3">
<h1>Housing Prices Prediction</h1>
<div class=article-metadata>
<span class=article-date>
Feb 3, 2022
</span>
<span class=middot-divider></span>
<span class=article-reading-time>
10 min read
</span>
<span class=middot-divider></span>
<span class=article-categories>
<i class="fas fa-folder mr-1"></i><a href=/category/r/>R</a>, <a href=/category/python/>Python</a>, <a href=/category/ml/>ML</a></span>
</div>
</div>
<div class="article-header container featured-image-wrapper mt-4 mb-4" style=max-width:962px;max-height:500px>
<div style=position:relative>
<img src=/post/2022-02-02-housing-price-prediction/featured_hue904a1c5f8eb495d3fde51a552c4a256_330166_1200x2500_fit_q75_h2_lanczos.webp width=962 height=500 alt class=featured-image>
</div>
</div>
<div class=article-container>
<div class=article-style>
<script src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/header-attrs/header-attrs.js></script>
<p>The goal of this short project is to document a fairly realistic ML pipeline, including data cleaning, data visualization, and model development, in both R and Python.</p>
<div id=python class="section level1">
<h1>Python</h1>
<div id=requisite-modules class="section level2">
<h2>Requisite modules</h2>
<pre class=python><code>import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedShuffleSplit
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.tree import DecisionTreeRegressor</code></pre>
</div>
<div id=import-data class="section level2">
<h2>Import data</h2>
<pre class=python><code>housing = pd.read_csv(
  &quot;https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv&quot;
)

# Get data structure
housing.info()</code></pre>
<pre><code># &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
# RangeIndex: 20640 entries, 0 to 20639
# Data columns (total 10 columns):
#  #   Column              Non-Null Count  Dtype  
# ---  ------              --------------  -----  
#  0   longitude           20640 non-null  float64
#  1   latitude            20640 non-null  float64
#  2   housing_median_age  20640 non-null  float64
#  3   total_rooms         20640 non-null  float64
#  4   total_bedrooms      20433 non-null  float64
#  5   population          20640 non-null  float64
#  6   households          20640 non-null  float64
#  7   median_income       20640 non-null  float64
#  8   median_house_value  20640 non-null  float64
#  9   ocean_proximity     20640 non-null  object 
# dtypes: float64(9), object(1)
# memory usage: 1.6+ MB</code></pre>
<p>We can also quickly summarize the housing data.</p>
<pre class=python><code>housing.describe()</code></pre>
<pre><code>#           longitude      latitude  ...  median_income  median_house_value
# count  20640.000000  20640.000000  ...   20640.000000        20640.000000
# mean    -119.569704     35.631861  ...       3.870671       206855.816909
# std        2.003532      2.135952  ...       1.899822       115395.615874
# min     -124.350000     32.540000  ...       0.499900        14999.000000
# 25%     -121.800000     33.930000  ...       2.563400       119600.000000
# 50%     -118.490000     34.260000  ...       3.534800       179700.000000
# 75%     -118.010000     37.710000  ...       4.743250       264725.000000
# max     -114.310000     41.950000  ...      15.000100       500001.000000
# 
# [8 rows x 9 columns]</code></pre>
<p>Now that we have a quick overview of the data, we can plot a histogram of all
numeric values.</p>
<pre class=python><code>housing.hist(bins = 50, figsize = (30, 15));
plt.show()</code></pre>
<p><img src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/figure-html/Numeric%20Hist-1.png width=2880></p>
<p>We’re going to bin the <code>median_income</code> variable to allow for stratified sampling
within income bins.</p>
<pre class=python><code>housing[&quot;median_income_bin&quot;] = pd.cut(
  housing[&quot;median_income&quot;],
  bins = [0, 1.5, 3, 4.5, 6, np.inf],
  labels = [1, 2, 3, 4, 5]
)

# Plot histogram of counts
housing[&quot;median_income_bin&quot;].hist();
plt.show()</code></pre>
<p><img src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/figure-html/Cut%20Income-3.png width=2880></p>
</div>
<div id=visualize-data class="section level2">
<h2>Visualize data</h2>
<p>Now, let’s visualize the median house prices by plotting them geographically.</p>
<pre class=python><code>(
  housing.
  rename(columns = {&quot;median_house_value&quot;: &quot;Median House Value&quot;}).
  plot(
    kind = &quot;scatter&quot;,
    x = &quot;longitude&quot;,
    y = &quot;latitude&quot;,
    alpha = 0.1,
    s = housing[&quot;population&quot;]/100,
    c = &quot;Median House Value&quot;,
    colormap = plt.get_cmap(&quot;jet&quot;),
    colorbar = True,
    title = &quot;Median House Prices by Population&quot;,
    xlabel = &quot;Longitude&quot;,
    ylabel = &quot;Latitude&quot;
  )
)

plt.show()</code></pre>
<p><img src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/figure-html/Prices%20Geo-5.png width=672></p>
<p>Let’s also look at the correlation between a few of our numeric variables.</p>
<pre class=python><code>pd.plotting.scatter_matrix(
  housing[
    [
     &quot;median_house_value&quot;,
     &quot;median_income&quot;,
     &quot;total_rooms&quot;,
     &quot;housing_median_age&quot;
    ]
  ],
  alpha = 0.1,
  figsize = (15, 8)
);

plt.show()</code></pre>
<p><img src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/figure-html/Cor%20Plot-7.png width=1440></p>
<p>Let’s specifically take a look at the relationship between <code>median_income</code> and
<code>median_house_value</code>.</p>
<pre class=python><code>(
  housing.
  rename(
    columns = {
      &quot;median_income&quot;: &quot;Median Income&quot;,
      &quot;median_house_value&quot;: &quot;Median House Value&quot;
    }
  ).
  plot(
    kind = &quot;scatter&quot;,
    x = &quot;Median Income&quot;,
    y = &quot;Median House Value&quot;,
    alpha = 0.1
  )
)

plt.show()</code></pre>
<p><img src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/figure-html/Income%20House%20Value-9.png width=672></p>
</div>
<div id=feature-engineering class="section level2">
<h2>Feature engineering</h2>
<p>We want to create a couple new features: <code>rooms_per_household</code> and
<code>bedrooms_per_room</code>.</p>
<pre class=python><code>housing[&quot;rooms_per_household&quot;] = housing[&quot;total_rooms&quot;]/housing[&quot;households&quot;]
housing[&quot;bedrooms_per_room&quot;] = housing[&quot;total_bedrooms&quot;]/housing[&quot;total_rooms&quot;]
housing[&quot;pop_per_household&quot;] = housing[&quot;population&quot;]/housing[&quot;households&quot;]</code></pre>
</div>
<div id=modeling-prep class="section level2">
<h2>Modeling prep</h2>
<p>Let’s do an 70-30 split of the data initially.</p>
<pre class=python><code>split = StratifiedShuffleSplit(
  n_splits = 1,
  test_size = 0.3,
  random_state = 123
)

for train_idx, test_idx in split.split(housing, housing[&quot;median_income_bin&quot;]):
  train = housing.loc[train_idx].drop(
    [&quot;median_income_bin&quot;, &quot;median_house_value&quot;],
    axis = 1
  )
  train_labels = housing.loc[train_idx, &quot;median_house_value&quot;]
  test = housing.loc[test_idx].drop(
    [&quot;median_income_bin&quot;, &quot;median_house_value&quot;],
    axis = 1
  )
  test_labels = housing.loc[test_idx, &quot;median_house_value&quot;]</code></pre>
<p>Now, let’s prep the data for modeling.</p>
<pre class=python><code># Numeric transformations
num_transform = Pipeline(
  [
    (&quot;imputer&quot;, SimpleImputer(strategy = &quot;median&quot;)),
    (&quot;scaler&quot;, StandardScaler())
  ]
)

full_transform = ColumnTransformer(
  [
    (
     &quot;numeric&quot;,
     num_transform,
     list(train.drop(&quot;ocean_proximity&quot;, axis = 1).columns)
    ),
    (&quot;categorical&quot;, OneHotEncoder(), [&quot;ocean_proximity&quot;])
  ]
)

train = full_transform.fit_transform(train)
test = full_transform.transform(test)</code></pre>
</div>
<div id=train-models class="section level2">
<h2>Train models</h2>
<p>Let’s quick chalk up a function to print CV metrics.</p>
<pre class=python><code>def metrics_summary(scores):
  print(&quot;Mean: &quot;, scores.mean().round(2))
  print(&quot;Standard Dev.: &quot;, scores.std().round(2))</code></pre>
<div id=linear-regression class="section level3">
<h3>Linear Regression</h3>
<p>The first model is a simple linear regression model.</p>
<pre class=python><code># Fit model
lin_reg_scores = np.sqrt(
  -cross_val_score(
     LinearRegression(),
     train,
     train_labels,
     scoring = &quot;neg_mean_squared_error&quot;,
     cv = 10
   )
)

# Summarize score info
metrics_summary(lin_reg_scores)</code></pre>
<pre><code># Mean:  68005.1
# Standard Dev.:  2417.76</code></pre>
</div>
<div id=decision-tree class="section level3">
<h3>Decision Tree</h3>
<p>The next model is a single decision tree model.</p>
<pre class=python><code># Fit model
tree_reg = np.sqrt(
  -cross_val_score(
     DecisionTreeRegressor(),
     train,
     train_labels,
     scoring = &quot;neg_mean_squared_error&quot;,
     cv = 10
   )
)

# Summarize score info
metrics_summary(tree_reg)</code></pre>
<pre><code># Mean:  71631.6
# Standard Dev.:  2614.03</code></pre>
</div>
<div id=random-forest class="section level3">
<h3>Random Forest</h3>
<p>Now, we will run a random forest model.</p>
<pre class=python><code># Fit model
forest_reg = np.sqrt(
  -cross_val_score(
     RandomForestRegressor(n_estimators = 30),
     train,
     train_labels,
     scoring = &quot;neg_mean_squared_error&quot;,
     cv = 10
   )
)

# Summarize score info
metrics_summary(forest_reg)</code></pre>
<pre><code># Mean:  51298.21
# Standard Dev.:  1698.51</code></pre>
<p>And finally, we will tune our random forest model via grid search.</p>
<pre class=python><code># Fit model
forest_reg_grid = GridSearchCV(
  RandomForestRegressor(),
  param_grid = {
    &quot;n_estimators&quot;: [30],
    &quot;min_samples_leaf&quot;: [5],
    &quot;max_features&quot;: [&quot;sqrt&quot;]
  },
  scoring = &quot;neg_mean_squared_error&quot;,
  cv = 5,
  return_train_score = True
)

forest_reg_grid_fit = forest_reg_grid.fit(train, train_labels)

# Get CV results
cv_results = forest_reg_grid_fit.cv_results_

# Summarize score info
for mean_sc, param in zip(cv_results[&quot;mean_test_score&quot;], cv_results[&quot;params&quot;]):
  print(&quot;Mean: &quot;, np.sqrt(-mean_sc).round(2))
  print(&quot;Parameters: &quot;, param)</code></pre>
<pre><code># Mean:  51821.79
# Parameters:  {&#39;max_features&#39;: &#39;sqrt&#39;, &#39;min_samples_leaf&#39;: 5, &#39;n_estimators&#39;: 30}</code></pre>
</div>
</div>
<div id=final-predictions class="section level2">
<h2>Final predictions</h2>
<pre class=python><code># Extract model
final_model = forest_reg_grid_fit.best_estimator_

# Make predictions
final_preds = final_model.predict(test)

# Final RMSE
print(
  &quot;Test RMSE: &quot;, np.sqrt(mean_squared_error(test_labels, final_preds)).round(2)
)</code></pre>
<pre><code># Test RMSE:  50810.13</code></pre>
</div>
</div>
<div id=r class="section level1">
<h1>R</h1>
<div id=requisite-packages class="section level2">
<h2>Requisite packages</h2>
<pre class=r><code>library(dplyr)
library(ggplot2)
library(purrr)
library(ranger)
library(readr)
library(rpart)
library(rsample)
library(sf)
library(tidyr)
library(viridis)
library(yardstick)</code></pre>
</div>
<div id=import-data-1 class="section level2">
<h2>Import data</h2>
<pre class=r><code>housing &lt;- read_csv(
  &quot;https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv&quot;,
  show_col_types = FALSE
)

# Get data structure
glimpse(housing)</code></pre>
<pre><code># Rows: 20,640
# Columns: 10
# $ longitude          &lt;dbl&gt; -122.23, -122.22, -122.24, -122.25, -122.25, -122.2~
# $ latitude           &lt;dbl&gt; 37.88, 37.86, 37.85, 37.85, 37.85, 37.85, 37.84, 37~
# $ housing_median_age &lt;dbl&gt; 41, 21, 52, 52, 52, 52, 52, 52, 42, 52, 52, 52, 52,~
# $ total_rooms        &lt;dbl&gt; 880, 7099, 1467, 1274, 1627, 919, 2535, 3104, 2555,~
# $ total_bedrooms     &lt;dbl&gt; 129, 1106, 190, 235, 280, 213, 489, 687, 665, 707, ~
# $ population         &lt;dbl&gt; 322, 2401, 496, 558, 565, 413, 1094, 1157, 1206, 15~
# $ households         &lt;dbl&gt; 126, 1138, 177, 219, 259, 193, 514, 647, 595, 714, ~
# $ median_income      &lt;dbl&gt; 8.3252, 8.3014, 7.2574, 5.6431, 3.8462, 4.0368, 3.6~
# $ median_house_value &lt;dbl&gt; 452600, 358500, 352100, 341300, 342200, 269700, 299~
# $ ocean_proximity    &lt;chr&gt; &quot;NEAR BAY&quot;, &quot;NEAR BAY&quot;, &quot;NEAR BAY&quot;, &quot;NEAR BAY&quot;, &quot;NE~</code></pre>
<p>Now, to get a quick summary of the data.</p>
<pre class=r><code>summary(housing)</code></pre>
<pre><code>#    longitude         latitude     housing_median_age  total_rooms   
#  Min.   :-124.3   Min.   :32.54   Min.   : 1.00      Min.   :    2  
#  1st Qu.:-121.8   1st Qu.:33.93   1st Qu.:18.00      1st Qu.: 1448  
#  Median :-118.5   Median :34.26   Median :29.00      Median : 2127  
#  Mean   :-119.6   Mean   :35.63   Mean   :28.64      Mean   : 2636  
#  3rd Qu.:-118.0   3rd Qu.:37.71   3rd Qu.:37.00      3rd Qu.: 3148  
#  Max.   :-114.3   Max.   :41.95   Max.   :52.00      Max.   :39320  
#                                                                     
#  total_bedrooms     population      households     median_income    
#  Min.   :   1.0   Min.   :    3   Min.   :   1.0   Min.   : 0.4999  
#  1st Qu.: 296.0   1st Qu.:  787   1st Qu.: 280.0   1st Qu.: 2.5634  
#  Median : 435.0   Median : 1166   Median : 409.0   Median : 3.5348  
#  Mean   : 537.9   Mean   : 1425   Mean   : 499.5   Mean   : 3.8707  
#  3rd Qu.: 647.0   3rd Qu.: 1725   3rd Qu.: 605.0   3rd Qu.: 4.7432  
#  Max.   :6445.0   Max.   :35682   Max.   :6082.0   Max.   :15.0001  
#  NA&#39;s   :207                                                        
#  median_house_value ocean_proximity   
#  Min.   : 14999     Length:20640      
#  1st Qu.:119600     Class :character  
#  Median :179700     Mode  :character  
#  Mean   :206856                       
#  3rd Qu.:264725                       
#  Max.   :500001                       
# </code></pre>
<p>Now that we have a quick overview of the data, we can plot a histogram of all
numeric values.</p>
<pre class=r><code>housing |&gt;
  select(where(is.numeric)) |&gt;
  pivot_longer(
    cols = everything(),
    names_to = &quot;variable&quot;,
    values_to = &quot;values&quot;
  ) |&gt;
  ggplot(aes(x = values)) +
  geom_histogram(fill = &quot;lightblue&quot;, bins = 50) +
  facet_wrap(
    ~ variable,
    nrow = 3,
    scales = &quot;free&quot;
  ) +
  labs(
    x = &quot;&quot;,
    y = &quot;&quot;
  ) +
  theme_minimal()</code></pre>
<p><img src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/figure-html/Numeric%20Hist%202-1.png width=1440></p>
<p>We’re going to bin the <code>median_income</code> variable to allow for stratified sampling
within income bins.</p>
<pre class=r><code>housing &lt;- housing |&gt;
  mutate(
    median_income_bin = cut(
      median_income,
      breaks = c(0, 1.5, 3, 4.5, 6, Inf),
      labels = c(1, 2, 3, 4, 5)
    )
  )

# Plot histogram of counts
hist(
  as.numeric(housing$median_income_bin),
  main = &quot;&quot;,
  xlab = &quot;Median Income Bin&quot;,
  ylab = &quot;Count&quot;,
  ylim = c(0, 8000)
)</code></pre>
<p><img src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/figure-html/Cut%20Income%202-1.png width=672></p>
</div>
<div id=visualize-data-1 class="section level2">
<h2>Visualize data</h2>
<p>Now, let’s visualize the median house prices by plotting them geographically.</p>
<pre class=r><code>housing |&gt;
  rename(
    &quot;Population&quot; = &quot;population&quot;,
    &quot;Median House Value&quot; = &quot;median_house_value&quot;
  ) |&gt;
  st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;)) |&gt;
  st_set_crs(value = 4326) |&gt;
  ggplot(
    aes(
      size = Population,
      color = `Median House Value`
    )
  ) +
  geom_sf(alpha = 0.1) +
  theme_minimal() +
  theme(
    axis.text = element_text(face = &quot;bold&quot;),
    legend.title = element_text(face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;)
  ) +
  scale_color_viridis(option = &quot;B&quot;) +
  guides(size = &quot;none&quot;) +
  labs(
    title = &quot;Median House Prices by Population&quot;,
    x = &quot;Longitude&quot;,
    y = &quot;Latitude&quot;
  )</code></pre>
<p><img src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/figure-html/Prices%20Geo%202-1.png width=1152></p>
<p>Let’s also look at the correlation between a few of our numeric variables.</p>
<pre class=r><code>plot(
  select(
    housing,
    c(
      &quot;median_house_value&quot;,
      &quot;median_income&quot;,
      &quot;total_rooms&quot;,
      &quot;housing_median_age&quot;
    )
  ),
  col = rgb(red = 0, green = 0, blue = 0, alpha = 0.1)
)</code></pre>
<p><img src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/figure-html/Cor%20Plot%202-1.png width=1152></p>
<p>Let’s specifically take a look at the relationship between <code>median_income</code> and
<code>median_house_value</code>.</p>
<pre class=r><code>housing |&gt;
  ggplot(aes(x = median_income, y = median_house_value)) +
  geom_point(alpha = 0.1) +
  theme_minimal() +
  theme(
    axis.text = element_text(face = &quot;bold&quot;),
    plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;)
  ) +
  labs(x = &quot;Median Income&quot;, y = &quot;Median House Value&quot;)</code></pre>
<p><img src=https://dmolitor.com/post/2022-02-02-housing-price-prediction/index_files/figure-html/Income%20House%20Value%202-1.png width=672></p>
</div>
<div id=feature-engineering-1 class="section level2">
<h2>Feature engineering</h2>
<p>We want to create a couple new features: <code>rooms_per_household</code> and
<code>bedrooms_per_room</code>.</p>
<pre class=r><code>housing &lt;- housing |&gt;
  mutate(
    rooms_per_household = total_rooms/households,
    bedrooms_per_room = total_bedrooms/total_rooms,
    pop_per_household = population/households
  )</code></pre>
</div>
<div id=modeling-prep-1 class="section level2">
<h2>Modeling prep</h2>
<p>Let’s do an 70-30 split of the data initially.</p>
<pre class=r><code>set.seed(123)
split &lt;- initial_split(
  data = housing,
  prop = 0.7,
  strata = &quot;median_income_bin&quot;
)

train &lt;- training(split) |&gt; select(-median_income_bin)
test &lt;- testing(split) |&gt; select(-median_income_bin)</code></pre>
<p>Now, let’s prep the data for modeling.</p>
<pre class=r><code># Get median values from training data
medians &lt;- suppressWarnings(
  lapply(train, median, na.rm = TRUE)
)

# Median impute
train &lt;- map2_df(
    .x = train,
    .y = medians,
    .f = ~ case_when(
      is.numeric(.x) ~ replace_na(.x, .y),
      TRUE ~ .x
    )
) |&gt;
  mutate(ocean_proximity = sort_factor(ocean_proximity))

test &lt;- map2_df(
    .x = test,
    .y = medians,
    .f = ~ case_when(
      is.numeric(.x) ~ replace_na(.x, .y),
      TRUE ~ .x
    )
) |&gt;
  mutate(ocean_proximity = sort_factor(ocean_proximity))</code></pre>
</div>
<div id=train-models-1 class="section level2">
<h2>Train models</h2>
<p>First, let’s split the training data into a 10-fold CV split and make a quick
function to print CV metrics.</p>
<pre class=r><code>train_cv &lt;- vfold_cv(train, v = 10)

# Summarise CV metrics
metrics_summary &lt;- function(scores) {
  print(paste0(&quot;Mean: &quot;, round(mean(scores), 2)))
  print(paste0(&quot;Standard Dev.: &quot;, round(sd(scores), 2)))
}</code></pre>
<div id=linear-regression-1 class="section level3">
<h3>Linear Regression</h3>
<p>The first model is a simple linear regression model.</p>
<pre class=r><code># Fit model
lin_reg_scores = map_dbl(
  train_cv$splits,
  function(i) {
    lin_mod &lt;- lm(median_house_value ~ ., data = i$data[i$in_id, ])
    lin_preds &lt;- predict(lin_mod, i$data[-i$in_id, ])
    rmse_vec(i$data[-i$in_id, ][[&quot;median_house_value&quot;]], lin_preds)
  }
)

# Summarize score info
metrics_summary(lin_reg_scores)</code></pre>
<pre><code># [1] &quot;Mean: 68071.59&quot;
# [1] &quot;Standard Dev.: 2677.06&quot;</code></pre>
</div>
<div id=decision-tree-1 class="section level3">
<h3>Decision Tree</h3>
<p>The next model is a single decision tree model.</p>
<pre class=r><code># Fit model
tree_reg_scores = map_dbl(
  train_cv$splits,
  function(i) {
    tree_mod &lt;- rpart(median_house_value ~ ., data = i$data[i$in_id, ])
    tree_preds &lt;- predict(tree_mod, i$data[-i$in_id, ])
    rmse_vec(i$data[-i$in_id, ][[&quot;median_house_value&quot;]], tree_preds)
  }
)

# Summarize score info
metrics_summary(tree_reg_scores)</code></pre>
<pre><code># [1] &quot;Mean: 72015.68&quot;
# [1] &quot;Standard Dev.: 2842.71&quot;</code></pre>
</div>
<div id=random-forest-1 class="section level3">
<h3>Random Forest</h3>
<p>Now, we will run a random forest model.</p>
<pre class=r><code># Fit model
forest_reg_scores = map_dbl(
  train_cv$splits,
  function(i) {
    forest_mod &lt;- ranger(median_house_value ~ ., data = i$data[i$in_id, ], 100)
    forest_preds &lt;- predict(forest_mod, i$data[-i$in_id, ])$predictions
    rmse_vec(i$data[-i$in_id, ][[&quot;median_house_value&quot;]], forest_preds)
  }
)

# Summarize score info
metrics_summary(tree_reg_scores)</code></pre>
<pre><code># [1] &quot;Mean: 72015.68&quot;
# [1] &quot;Standard Dev.: 2842.71&quot;</code></pre>
<p>And finally, we will tune our random forest model via grid search.</p>
<pre class=r><code># Create grid
param_grid &lt;- expand.grid(num.trees = 100, mtry = 5, min.node.size = 3)

# Fit model
forest_reg_grid &lt;- map(
  1:nrow(param_grid),
  function(grid_idx) {
    map_dbl(
      train_cv$splits,
      function(cv_fold) {
        # LOO CV Model
        forest_mod &lt;- ranger(
          median_house_value ~ .,
          data = cv_fold$data[cv_fold$in_id, ],
          num.trees = param_grid[grid_idx, ]$num.trees,
          mtry = param_grid[grid_idx, ]$mtry,
          min.node.size = param_grid[grid_idx, ]$min.node.size
        )
        # OOS Predictions
        forest_preds &lt;- predict(forest_mod, cv_fold$data[-cv_fold$in_id, ])$predictions
        # Calculate RMSE
        rmse_vec(
          truth = cv_fold$data[-cv_fold$in_id, ][[&quot;median_house_value&quot;]],
          estimate = forest_preds
        )
      }
    )
  }
)

# Get best model
best_mod &lt;- which.min(map_dbl(forest_reg_grid, mean))
forest_reg_grid_fit = ranger(
  median_house_value ~ .,
  data = train,
  num.trees = param_grid[best_mod, ]$num.trees,
  mtry = param_grid[best_mod, ]$mtry,
  min.node.size = param_grid[best_mod, ]$min.node.size
)

# Summarize score info
walk(forest_reg_grid, metrics_summary)</code></pre>
<pre><code># [1] &quot;Mean: 48819.23&quot;
# [1] &quot;Standard Dev.: 1829.59&quot;</code></pre>
</div>
</div>
<div id=final-predictions-1 class="section level2">
<h2>Final predictions</h2>
<pre class=r><code># Extract model
final_model = forest_reg_grid_fit

# Make predictions
final_preds = predict(final_model, test)$predictions

# Final RMSE
cat(
  &quot;Test RMSE:&quot;, rmse_vec(test$median_house_value, final_preds)
)</code></pre>
<pre><code># Test RMSE: 49288.67</code></pre>
</div>
</div>
</div>
<div class="media author-card content-widget-hr">
<a href=https://dmolitor.com><img class="avatar mr-3 avatar-circle" src=/author/daniel-molitor/avatar_hu3bdbe7bd9380974ee4c49e4fa9e4a1b5_1768872_270x270_fill_q75_lanczos_center.jpg alt="Daniel Molitor"></a>
<div class=media-body>
<h5 class=card-title><a href=https://dmolitor.com>Daniel Molitor</a></h5>
<h6 class=card-subtitle>Associate Data Scientist</h6>
<ul class=network-icon aria-hidden=true>
<li>
<a href=mailto:molitdj97@gmail.com>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href=https://twitter.com/dmol97 target=_blank rel=noopener>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href=https://github.com/dmolitor target=_blank rel=noopener>
<i class="fab fa-github"></i>
</a>
</li>
<li>
<a href=https://www.linkedin.com/in/molitor-daniel target=_blank rel=noopener>
<i class="fab fa-linkedin"></i>
</a>
</li>
</ul>
</div>
</div>
</div>
</article>
</div>
<div class=page-footer>
<div class=container>
<footer class=site-footer>
<p class=powered-by>
Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.
</p>
</footer>
</div>
</div>
<div id=modal class="modal fade" role=dialog>
<div class=modal-dialog>
<div class=modal-content>
<div class=modal-header>
<h5 class=modal-title>Cite</h5>
<button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span>
</button>
</div>
<div class=modal-body>
<pre><code class="tex hljs"></code></pre>
</div>
<div class=modal-footer>
<a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank>
<i class="fas fa-copy"></i> Copy
</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank>
<i class="fas fa-download"></i> Download
</a>
<div id=modal-error></div>
</div>
</div>
</div>
</div>
<script src=/js/vendor-bundle.min.b73dfaac3b6499dc997741748a7c3fe2.js></script>
<script src=https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/python.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
<script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script>
<script src=/js/wowchemy-headroom.1cb9e2fc8399acee94eab837265b73bf.js type=module></script>
<script src=/en/js/wowchemy.min.247fd8f54253895301106e3006f53f38.js></script>
<script async defer src=https://buttons.github.io/buttons.js></script>
</body>
</html>