---
pagetitle: "Research"
toc: false
page-layout: article
include-after-body:
  text: |
    <script type="application/javascript" src="light-dark.js"></script>
---

## Publications

<a href="https://doi.org/10.1145/3428125" style="text-decoration: none;"><b>Delivering Unemployment Assistance in Times of Crisis: Scalable Cloud Solutions Can Keep Essential Government Programs Running and Supporting Those in Need</b></a>. Mintaka Angell, et al. (2020). <i>Digital Government: Research and Practice</i>.
<details>
  <summary>Abstract</summary>
  <p class="dynamic-text" style="background-color: #f0f0f0; padding: 1em;">
    The COVID-19 public health emergency caused widespread economic shutdown and 
    unemployment. The resulting surge in Unemployment Insurance claims threatened to
    overwhelm the legacy systems state workforce agencies rely on to collect,
    process, and pay claims. In Rhode Island, we developed a scalable cloud
    solution to collect Pandemic Unemployment Assistance claims as part of a
    new program created under the Coronavirus Aid, Relief and Economic
    Security Act to extend unemployment benefits to independent contractors
    and gig-economy workers not covered by traditional Unemployment Insurance.
    Our new system was developed, tested, and deployed within 10 days following
    the passage of the Coronavirus Aid, Relief and Economic Security Act, making
    Rhode Island the first state in the nation to collect, validate, and pay
    Pandemic Unemployment Assistance claims. A cloud-enhanced interactive voice
    response system was deployed a week later to handle the corresponding surge
    in weekly certifications for continuing unemployment benefits. Cloud solutions
    can augment legacy systems by offloading processes that are more efficiently
    handled in modern scalable systems, reserving the limited resources of
    legacy systems for what they were originally designed. This agile use of
    combined technologies allowed Rhode Island to deliver timely Pandemic
    Unemployment Assistance benefits with an estimated cost savings of
    $502,000 (representing a 411% return on investment).
  </p>
</details>

## Pre-prints

<a href="https://osf.io/preprints/socarxiv/69y2j_v1" style="text-decoration: none;"><b>Adaptive Randomization in Conjoint Survey Experiments</b></a>. Jennah Gosciak, Daniel Molitor, Ian Lundberg. <i>SocArXiv</i>.
<details>
  <summary>Abstract</summary>
  <p class="dynamic-text" style="background-color: #f0f0f0; padding: 1em;">
    Human choices are often multi-dimensional. For example, a person deciding
    which of two immigrants is more worthy of admission to a country might
    weigh the prospective immigrants' education, age, country of origin,
    and employment history. Conjoint experiments have rapidly generated new
    insight into these multidimensional choices. By independently randomizing
    the attributes of a pair of fictitious profiles, researchers summarize the
    average contribution that each attribute makes to an overall choice. But
    what if the effect of one attribute depends on the values of other
    attributes? We present a method that uses data-adaptive experimentation
    to search for heterogeneity in the effect of one focal attribute as a
    function of all other attributes. Our empirical application of this method
    shows that U.S. adults weigh the education of an immigrant much more heavily
    for certain immigrants than for others. By targeting the heterogeneous
    effects of a focal attribute, our approach complements conjoint designs
    that target the average effects of all attributes.
  </p>
</details>

<a href="https://files.osf.io/v1/resources/rkw3e/providers/osfstorage/65b132bbebe5e6067ff5e720?action=download&direct&version=1" style="text-decoration: none;"><b>The Causal Effect of Parent Occupation on Child Occupation: A Multivalued Treatment with Positivity Constraints</b></a>. Ian Lundberg, Jennie Brand, Daniel Molitor. Conditionally accepted, <i>Sociological Methods and Research</i>.
<details>
  <summary>Abstract</summary>
  <p class="dynamic-text" style="background-color: #f0f0f0; padding: 1em;">
    Contemporary social mobility research often adopts an ostensibly descriptive
    goal: to document associations between parent and child socioeconomic outcomes and their
    variation over time and place. To complement descriptive research, we adopt a causal
    goal: to estimate the degree to which parent occupation causes child occupation. We
    formalize this causal goal in the potential outcomes framework to define precise 
    counterfactuals. We highlight a difficulty connected to the positivity assumption for causal
    inference: when the treatment is parent occupation, many counterfactuals never happen in
    observed data. Parents without college degrees are never employed as physicians,
    for instance. We show how to select causal estimands involving only the
    counterfactuals that can be studied with data. We demonstrate our approach using 
    the National Longitudinal Survey of Youth 1979. Our causal approach points to 
    open questions about how specific aspects of family background, such as 
    parent occupation, causally shape the life chances of children.
  </p>
</details>

<a href="https://doi.org/10.31219/osf.io/thg23" style="text-decoration: none;"><b>Estimating Value-added Returns to Labor Training Programs with Causal Machine Learning</b></a>. Mintaka Angell, et al. <i>OSF Pre-prints</i>.
<details>
  <summary>Abstract</summary>
  <p class="dynamic-text" style="background-color: #f0f0f0; padding: 1em;">
    The mismatch between the skills that employers seek and the skills that workers possess
    will increase substantially as demand for technically skilled workers accelerates.
    Skill mismatches disproportionately affect low-income workers and those within
    industries where relative demand growth for technical skills is strongest.
    As a result, much emphasis is placed on reskilling workers to ease transitions
    into new careers. However, utilization of training programs may be sub-optimal
    if workers are uncertain about the returns to their investment in training.
    While the U.S. spends billions of dollars annually on reskilling programs and
    unemployment insurance, there are few measures of program effectiveness that
    workers or government can use to guide training investment and ensure valuable
    reskilling outcomes. We demonstrate a causal machine learning method for
    estimating the value-added returns to training programs in Rhode Island, where
    enrollment increases future quarterly earnings by $605 on average, ranging from
    -$1,570 to $3,470 for individual programs. In a nationwide survey (N=2,014),
    workers prefer information on the value-added returns to earnings following
    training enrollment, establishing the importance of our estimates for guiding
    training decisions. For every 10% increase in expected earnings, workers are
    17.4% more likely to express interest in training. State and local governments
    can provide this preferred information on value-added returns using our method
    and existing administrative data.
  </p>
</details>

## Works in Progress

<a href="https://www.dmolitor.com/blog/posts/conjoint_analysis/" style="text-decoration: none;"><b>Anytime-Valid Inference in Conjoint Experiments</b></a>. Daniel Molitor.
<details>
  <summary>Abstract</summary>
  <p class="dynamic-text" style="background-color: #f0f0f0; padding: 1em;">
    Conjoint experiments have become increasingly popular for studying how
    multiple attributes influence decision-making. However, determining the
    optimal sample size required to achieve adequate statistical power in
    conjoint experiments is challenging; conventional power analysis requires
    many assumptions to hold simultaneously, and can easily under- or
    over-estimate the necessary sample size. To overcome these limitations,
    I propose an alternative approach grounded in recent advances in
    anytime-valid inference. Rather than relying on conventional power
    analysis, this approach introduces anytime-valid confidence sequences
    (CSs) and corresponding p-values for key conjoint estimands, including
    the AMCE, ACIE, and marginal means. These procedures are computationally
    simple---building on standard regression outputs, guarantee valid Type I
    error control at any stopping point, and enable practitioners to continuously
    monitor their empirical estimates and implement data-driven stopping rules
    once their estimates of interest achieve sufficient statistical power or
    precision. In simulations calibrated to real-world conjoint studies, I show
    that this approach preserves nominal coverage, achieves comparable power
    to standard fixed-n approaches, and yields average sample savings of 10â€“40\%
    across a broad range of effect sizes, sample sizes, and attribute levels.
    This approach gives practitioners a principled, efficient way to determine
    when to stop data collection without relying on pre-specified power
    analyses.
  </p>
</details>

<a href="https://www.dmolitor.com/blog/posts/robust_adaptive_exp/" style="text-decoration: none;"><b>Balancing Power and Efficiency in Adaptive Experiments</b></a>. Daniel Molitor, Samantha Gold.
<details>
  <summary>Abstract</summary>
  <p class="dynamic-text" style="background-color: #f0f0f0; padding: 1em;">
    This paper introduces the Modified Mixture Adaptive Design (MADMod),
    an experimental design for conducting adaptive experiments with multiple
    treatment arms that addresses both efficiency and robust inference. Building
    on the Mixture Adaptive Design (MAD) framework, MADMod retains anytime-valid
    confidence sequences---allowing experiments to conclude dynamically---while
    systematically reallocating samples to ensure each arm achieves sufficient
    statistical power. By integrating importance weights that decay once an armâ€™s
    average treatment effect is detected as significant, MADMod prevents
    under-allocation to suboptimal arms without sacrificing the efficiency gains
    of multi-armed bandits. Simulation results demonstrate that, compared to
    standard adaptive designs, MADMod substantially reduces Type 2 error rates
    and offers more precise inference across all treatments. This allows
    researchers to harness the benefits of adaptive sampling and early stopping
    while maintaining well-powered evaluations of every treatment arm.
  </p>
</details>